[{"path":"/articles/models.html","id":"gaussian-linear-regression","dir":"Articles","previous_headings":"","what":"Gaussian (linear regression)","title":"Models","text":"linear regression, loss function simply squared error loss: $$ L(\\bb|\\X,\\y) = \\frac{1}{2} \\norm{\\y-\\X\\bb}_2^2; $$ proportional negative log-likelihood model yy follows Gaussian distribution constant variance mean equal $\\X\\bb$. fit penalized linear regression model grpreg:","code":"fit <- grpreg(X, y, group)"},{"path":"/articles/models.html","id":"binomial-logistic-regression","dir":"Articles","previous_headings":"","what":"Binomial (logistic regression)","title":"Models","text":"logistic regression, loss function : $$ L(\\bb|\\X,\\y) = -\\sum_{:y_i=1}\\log\\ph_i - \\sum_{:y_i=0}\\log(1-\\ph_i); $$ negative log-likelihood binomial distribution probabilities $P(Y_i=1)=\\ph_i$ given : $$ \\ph_i = \\frac{\\exp(\\eta_i)}{1+\\eta_i}, $$ $\\= \\X\\bb$ denotes linear predictors. fit penalized logistic regression model grpreg:","code":"fit <- grpreg(X, y, group, family='binomial')"},{"path":"/articles/models.html","id":"poisson","dir":"Articles","previous_headings":"","what":"Poisson","title":"Models","text":"Poisson regression, loss function : $$ L(\\bb|\\X,\\y) = 2\\sum_i \\left\\{y_i\\log y_i - y_i\\log \\mu_i + mu_i - y_i\\right\\}; $$ note terms constant respect μi\\mu_i can therefore ignored optimization. Twice loss deviance Poisson distribution $Y_i \\sim \\text{Pois}(\\mh_i)$ rate parameter given : $$ \\mh_i = \\exp(\\eta_i). $$ fit penalized Poisson regression model grpreg:","code":"fit <- grpreg(X, y, group, family='poisson')"},{"path":"/articles/models.html","id":"cox-proportional-hazards","dir":"Articles","previous_headings":"","what":"Cox proportional hazards","title":"Models","text":"models fall category distributions known exponential families (hence family) argument. grpreg also allows users fit Cox proportional hazards models, although models fall outside framework therefore fit using different function, grpsurv. Cox regression, negative log partial likelihood $$ L(\\bb|\\X,\\y) = -2\\sum_{j=1}^{m} d_j \\eta_j + 2\\sum_{j=1}^{m} d_j \\log\\left\\{\\sum_{\\R_j} \\exp(\\eta_i)\\right\\}, $$ t1<t2<…<tmt_1 < t_2 < \\ldots < t_m denotes increasing list unique failure times indexed jj RjR_j denotes set observations still risk time tjt_j, known risk set. Lung data (see ?Lung details) provides example time--event data can used Cox regression. Loading data set R, fit penalized Cox regression model, , can call plot, coef, predict, etc. fit: Cross-validation similar:  addition quantities like coefficients number nonzero coefficients predict returns types models, predict() grpsurv object can also estimate baseline hazard (using Kalbfleish-Prentice method) therefore, survival function. method plot resulting function also available:  multiple subjects involved prediction:","code":"data(Lung) X <- Lung$X y <- Lung$y group <- Lung$group fit <- grpsurv(X, y, group) coef(fit, lambda=0.1) #        trt     karno1     karno2     karno3  diagtime1  diagtime2       age1  #  0.0000000 -4.6535992  0.4641241 -0.3283532  0.0000000  0.0000000  0.0000000  #       age2       age3      prior   squamous      small      adeno      large  #  0.0000000  0.0000000  0.0000000 -0.2613796  0.1320625  0.2666665 -0.1424394 set.seed(1) cvfit <- cv.grpsurv(X, y, group) par(mfrow=c(1,2)) plot(cvfit, type='cve') plot(cvfit, type='rsq') S <- predict(fit, X[1,], type='survival', lambda=0.02) S(365)   # Estiamted survival at 1 year # [1] 0.09995821 plot(S, xlim=c(0,200)) S <- predict(fit, X, type='survival', lambda=0.02) S[[1]](365)  # Estimated survival at 1 year for subject 1 # [1] 0.09995821 S[[2]](365)  # Estimated survival at 1 year for subject 2 # [1] 0.142846 plot(S, xlim=c(0,200))"},{"path":"/articles/penalties.html","id":"group-selection","dir":"Articles","previous_headings":"","what":"Group selection","title":"Penalties","text":"penalties sparse group level – coefficients within group either equal zero none equal zero. use penalties, please cite Breheny P Huang J (2015). Group descent algorithms nonconvex penalized linear logistic regression models grouped predictors. Statistics Computing, 25: 173-187. [pdf]. article goes mathematical details, discusses issues standardization group sense, provides references. group lasso originally proposed Yuan M. Lin Y. (2006) Model selection estimation regression grouped variables. Journal Royal Statistical Society Series B, 68: 49-67.","code":""},{"path":"/articles/penalties.html","id":"group-lasso","dir":"Articles","previous_headings":"Group selection","what":"Group lasso","title":"Penalties","text":"$$ P(\\beta) = \\lam \\sum_j \\norm{\\bb_j}_2 $$","code":"grpreg(X, y, group, penalty=\"grLasso\")"},{"path":"/articles/penalties.html","id":"group-mcp","dir":"Articles","previous_headings":"Group selection","what":"Group MCP","title":"Penalties","text":"$$ P(\\bb) = \\sum_j \\textrm{MCP}_{\\lam, \\gamma}(\\norm{\\bb_j}_2) $$ $\\textrm{MCP}_{\\lam, \\gamma}(\\cdot)$ denotes MCP penalty regularization parameter $\\lam$ tuning parameter γ\\gamma.","code":"grpreg(X, y, group, penalty=\"grMCP\")"},{"path":"/articles/penalties.html","id":"group-scad","dir":"Articles","previous_headings":"Group selection","what":"Group SCAD","title":"Penalties","text":"$$ P(\\bb) = \\sum_j \\textrm{SCAD}_{\\lam, \\gamma}(\\norm{\\bb_j}_2) $$ $\\textrm{SCAD}_{\\lam, \\gamma}(\\cdot)$ denotes SCAD penalty regularization parameter $\\lam$ tuning parameter γ\\gamma.","code":"grpreg(X, y, group, penalty=\"grSCAD\")"},{"path":"/articles/penalties.html","id":"bi-level-selection","dir":"Articles","previous_headings":"","what":"Bi-level selection","title":"Penalties","text":"penalties sparse group individual levels. groups, coefficients equal zero. However, even group selected, coefficients within group may still zero.","code":""},{"path":"/articles/penalties.html","id":"group-exponential-lasso-gel","dir":"Articles","previous_headings":"Bi-level selection","what":"Group exponential lasso (GEL)","title":"Penalties","text":"$$ P(\\beta) = \\sum_j f_{\\lam, \\tau}(\\norm{\\bb_j}_1) $$ f(⋅)f(\\cdot) denotes exponential penalty regularization parameter $\\lam$ tuning parameter τ\\tau: $$ f_{\\lam, \\tau}(\\theta) = \\frac{\\lam^2}{\\tau}\\left\\{1-\\exp\\left(-\\frac{\\tau\\theta}{\\lam}\\right)\\right\\} $$ use GEL penalty, please cite Breheny P (2015). group exponential lasso bi-level variable selection. Biometrics, 71: 731-740. [pdf].","code":"grpreg(X, y, group, penalty=\"gel\")"},{"path":"/articles/penalties.html","id":"composite-mcp","dir":"Articles","previous_headings":"Bi-level selection","what":"Composite MCP","title":"Penalties","text":"$$ P(\\bb) = \\sum_j \\textrm{MCP}_{\\lam, \\gam_1} \\left( \\sum_k \\textrm{MCP}_{\\lam, \\gam_2} (\\abs{\\beta_{jk}}) \\right) $$ $\\textrm{MCP}_{\\lam, \\gamma}(\\cdot)$ denotes MCP penalty regularization parameter $\\lam$ tuning parameter γ\\gamma. use composite MCP penalty, please cite either following papers: Breheny P Huang J (2009). Penalized methods bi-level variable selection. Statistics Interface, 2: 369-380. [pdf] Huang J, Breheny P Ma S (2012). selective review group selection high-dimensional models. Statistical Science, 27: 481-499. [pdf] Please note confusion around name “group MCP”. first paper (2009), composite MCP penalty referred “group MCP” penalty; second paper (2012), reviewing various kinds group penalties proposed, recommended changing name “composite MCP” avoid confusion “group MCP” defined .","code":"grpreg(X, y, group, penalty=\"cMCP\")"},{"path":"/articles/penalties.html","id":"group-bridge","dir":"Articles","previous_headings":"Bi-level selection","what":"Group bridge","title":"Penalties","text":"$$ P(\\bb) = \\lambda \\sum_j K_j^\\gamma \\norm{\\bb_j}_1^\\gamma $$ KjK_j denotes number elements group jj. Please note group bridge penalty uses different algorithm penalties. Due nature penalty, model fitting slower less stable group bridge models. , fact, main motivation GEL penalty Section~: offer tractable alternative group bridge similar estimation properties much better behaved numerical optimization perspective. use group bridge penalty, please cite either following papers: Huang J, Ma S, Xie H Zhang C (2009). group bridge approach variable selection. Biometrika, 96: 339-355. Breheny P Huang J (2009). Penalized methods bi-level variable selection. Statistics Interface, 2: 369-380. [pdf] first paper proposed method; second paper proposed algorithm used grpreg package.","code":"gBridge(X, y, group)"},{"path":"/articles/penalties.html","id":"specifying-an-additional-ridge-component","dir":"Articles","previous_headings":"","what":"Specifying an additional ridge component","title":"Penalties","text":"penalties previous section, grpreg allows specification additional ridge (L2L_2) component penalty. set $\\lam_1 = \\alpha\\lam$ $\\lam_2=(1-\\alpha)\\lam$, penalty given $$ P(\\bb) = P_1(\\bb|\\lam_1) + \\frac{\\lam_2}{2}\\norm{\\bb}_2^2, $$ P1P_1 penalties earlier sections. , example fit model penalty $$ P(\\beta) = 0.75\\lam \\sum_j \\norm{\\bb_j}_2 + \\frac{0.25\\lam}{2}\\norm{\\bb}_2^2. $$","code":"grpreg(X, y, group, penalty=\"grLasso\", alpha=0.75)"},{"path":"/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Patrick Breheny. Author, maintainer. Yaohui Zeng. Contributor. Ryan Kurth. Contributor.","code":""},{"path":"/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Breheny P, Huang J (2015). “Group descent algorithms nonconvex penalized linear logistic regression models grouped predictors.” Statistics Computing, 25(2), 173–187. doi:10.1007/s11222-013-9424-2, https://dx.doi.org/10.1007/s11222-013-9424-2. Breheny P (2015). “group exponential lasso bi-level variable selection.” Biometrics, 71(3), 731–740. doi:10.1111/biom.12300, https://dx.doi.org/10.1111/biom.12300. Breheny P, Huang J (2009). “Penalized methods bi-level variable selection.” Statistics Interface, 2, 369–380. doi:10.4310/sii.2009.v2.n3.a10.","code":"@Article{,   author = {Patrick Breheny and Jian Huang},   title = {Group descent algorithms for nonconvex penalized linear and logistic regression models with grouped predictors},   journal = {Statistics and Computing},   year = {2015},   volume = {25},   number = {2},   pages = {173--187},   doi = {10.1007/s11222-013-9424-2},   url = {https://dx.doi.org/10.1007/s11222-013-9424-2}, } @Article{,   author = {Patrick Breheny},   title = {The group exponential lasso for bi-level variable selection},   journal = {Biometrics},   year = {2015},   volume = {71},   number = {3},   pages = {731--740},   doi = {10.1111/biom.12300},   url = {https://dx.doi.org/10.1111/biom.12300}, } @Article{,   author = {Patrick Breheny and Jian Huang},   title = {Penalized methods for bi-level variable selection},   journal = {Statistics and Its Interface},   year = {2009},   volume = {2},   pages = {369--380},   doi = {10.4310/sii.2009.v2.n3.a10}, }"},{"path":"/index.html","id":"regularization-paths-for-regression-models-with-grouped-covariates","dir":"","previous_headings":"","what":"Regularization Paths for Regression Models with Grouped Covariates","title":"Regularization Paths for Regression Models with Grouped Covariates","text":"grpreg R package fitting regularization path linear regression, GLM, Cox regression models grouped penalties. includes group selection methods group lasso, group MCP, group SCAD well bi-level selection methods group exponential lasso, composite MCP, group bridge. Utilities carrying cross-validation well post-fitting visualization, summarization, prediction also provided.","code":""},{"path":"/index.html","id":"install","dir":"","previous_headings":"","what":"Install","title":"Regularization Paths for Regression Models with Grouped Covariates","text":"install latest release version CRAN: install.packages(\"grpreg\") install latest development version GitHub: remotes::install_github(\"pbreheny/grpreg\")","code":""},{"path":"/index.html","id":"get-started","dir":"","previous_headings":"","what":"Get started","title":"Regularization Paths for Regression Models with Grouped Covariates","text":"See “getting started” vignette","code":""},{"path":"/index.html","id":"learn-more","dir":"","previous_headings":"","what":"Learn more","title":"Regularization Paths for Regression Models with Grouped Covariates","text":"specific details models penalties used grpreg available “Learn ” menu.","code":""},{"path":"/index.html","id":"algorithms","dir":"","previous_headings":"","what":"Algorithms","title":"Regularization Paths for Regression Models with Grouped Covariates","text":"detail algorithms used fit penalized models, see papers. Breheny, P. Huang, J. (2009) Penalized methods bi-level variable selection. Statistics interface, 2: 369-380. Breheny, P. Huang, J. (2015) Group descent algorithms nonconvex penalized linear logistic regression models grouped predictors. Statistics Computing, 25: 173-187.","code":""},{"path":"/reference/AUC.cv.grpsurv.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculates AUC for cv.grpsurv objects — AUC.cv.grpsurv","title":"Calculates AUC for cv.grpsurv objects — AUC.cv.grpsurv","text":"Calculates cross-validated AUC (concordance) \"cv.grpsurv\" object.","code":""},{"path":"/reference/AUC.cv.grpsurv.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculates AUC for cv.grpsurv objects — AUC.cv.grpsurv","text":"","code":"# S3 method for class 'cv.grpsurv' AUC(obj, ...)  AUC(obj, ...)"},{"path":"/reference/AUC.cv.grpsurv.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculates AUC for cv.grpsurv objects — AUC.cv.grpsurv","text":"obj cv.grpsurv object. must run cv.grpsurv() option returnY=TRUE order AUC work. ... S3 method compatibility.","code":""},{"path":"/reference/AUC.cv.grpsurv.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Calculates AUC for cv.grpsurv objects — AUC.cv.grpsurv","text":"area curve (AUC), equivalently, concordance statistic (C), calculated according procedure described van Houwelingen Putter (2011). function calls survival::concordancefit(), except cross-validated linear predictors used guard overfitting. Thus, values returned AUC.cv.grpsurv() lower obtain concordancefit() fit full (unpenalized) model.","code":""},{"path":"/reference/AUC.cv.grpsurv.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Calculates AUC for cv.grpsurv objects — AUC.cv.grpsurv","text":"van Houwelingen H, Putter H (2011). Dynamic Prediction Clinical Survival Analysis. CRC Press.","code":""},{"path":[]},{"path":"/reference/AUC.cv.grpsurv.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculates AUC for cv.grpsurv objects — AUC.cv.grpsurv","text":"","code":"data(Lung) X <- Lung$X y <- Lung$y group <- Lung$group  cvfit <- cv.grpsurv(X, y, group, returnY=TRUE) head(AUC(cvfit)) #> [1] 0.6327806 0.6833826 0.6964448 0.7033167 0.7109269 0.7163221 ll <- log(cvfit$fit$lambda) plot(ll, AUC(cvfit), xlim=rev(range(ll)), lwd=3, type='l',      xlab=expression(log(lambda)), ylab='AUC', las=1)"},{"path":"/reference/Birthwt.html","id":null,"dir":"Reference","previous_headings":"","what":"Risk Factors Associated with Low Infant Birth Weight — Birthwt","title":"Risk Factors Associated with Low Infant Birth Weight — Birthwt","text":"Birthwt data contains 189 observations, 16 predictors, outcome, birthweight, available continuous measure binary indicator low birth weight.data collected Baystate Medical Center, Springfield, Mass 1986. data frame reparameterization birthwt data frame MASS package.","code":""},{"path":"/reference/Birthwt.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Risk Factors Associated with Low Infant Birth Weight — Birthwt","text":"","code":"Birthwt"},{"path":"/reference/Birthwt.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Risk Factors Associated with Low Infant Birth Weight — Birthwt","text":"Birthwt object list containing four elements (X, bwt, low, group): bwt Birth weight kilograms low Indicator birth weight less 2.5kg group Vector describing columns X grouped X matrix 189 observations (rows) 16 predictor variables (columns). matrix X contains following columns: age1,age2,age3 Orthogonal polynomials first, second, third degree representing mother's age years lwt1,lwt2,lwt3 Orthogonal polynomials first, second, third degree representing mother's weight pounds last menstrual period white,black Indicator functions mother's race; \"\" reference group smoke Smoking status pregnancy ptl1,ptl2m Indicator functions one two previous premature labors, respectively. previous premature labors reference category. ht History hypertension ui Presence uterine irritability ftv1,ftv2,ftv3m Indicator functions one, two, three physician visits first trimester, respectively. visits reference category.","code":""},{"path":"/reference/Birthwt.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Risk Factors Associated with Low Infant Birth Weight — Birthwt","text":"https://cran.r-project.org/package=MASS","code":""},{"path":"/reference/Birthwt.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Risk Factors Associated with Low Infant Birth Weight — Birthwt","text":"Venables, W. N. Ripley, B. D. (2002). Modern Applied Statistics S. Fourth edition. Springer. Hosmer, D.W. Lemeshow, S. (1989) Applied Logistic Regression. New York: Wiley","code":""},{"path":[]},{"path":"/reference/Birthwt.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Risk Factors Associated with Low Infant Birth Weight — Birthwt","text":"","code":"data(Birthwt) hist(Birthwt$bwt, xlab=\"Child's birth weight\", main=\"\")  table(Birthwt$low) #>  #>   0   1  #> 130  59  ## See examples in ?birthwt (MASS package) ##   for more about the data set ## See examples in ?grpreg for use of this data set ##   with group penalized regression models"},{"path":"/reference/Lung.html","id":null,"dir":"Reference","previous_headings":"","what":"VA lung cancer data set — Lung","title":"VA lung cancer data set — Lung","text":"Data randomised trial two treatment regimens lung cancer. standard survival analysis data set classic textbook Kalbfleisch Prentice.","code":""},{"path":"/reference/Lung.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"VA lung cancer data set — Lung","text":"","code":"Lung"},{"path":"/reference/Lung.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"VA lung cancer data set — Lung","text":"list two objects: y X y two column matrix (Surv object) containing follow-time (days) indicator variable whether patient died study . X matrix 137 observations (rows) 9 predictor variables (columns). remainder list describes columns X trt Treatment indicator (1=control group, 2=treatment group) karno Karnofsky performance score (0=bad, 100=good) diagtime Time diagnosis randomization (months) age Age (years, baseline) prior Prior therapy (0=, 1=yes) squamous Indicator whether cancer type squamous cell carcinoma (0=, 1=yes) small Indicator whether cancer type small cell lung cancer (0=, 1=yes) adeno Indicator whether cancer type adenocarcinoma (0=, 1=yes) large Indicator whether cancer type large cell carcinoma (0=, 1=yes)","code":""},{"path":"/reference/Lung.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"VA lung cancer data set — Lung","text":"https://cran.r-project.org/package=survival","code":""},{"path":"/reference/Lung.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"VA lung cancer data set — Lung","text":"Kalbfleisch D Prentice RL (1980), Statistical Analysis Failure Time Data. Wiley, New York.","code":""},{"path":[]},{"path":"/reference/birthwt.grpreg.html","id":null,"dir":"Reference","previous_headings":"","what":"Risk Factors Associated with Low Infant Birth Weight — birthwt.grpreg","title":"Risk Factors Associated with Low Infant Birth Weight — birthwt.grpreg","text":"version data set deprecated supported future versions.  Please use Birthwt instead.","code":""},{"path":"/reference/birthwt.grpreg.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Risk Factors Associated with Low Infant Birth Weight — birthwt.grpreg","text":"","code":"birthwt.grpreg"},{"path":"/reference/birthwt.grpreg.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Risk Factors Associated with Low Infant Birth Weight — birthwt.grpreg","text":"data frame contains following columns: low Indicator birth weight less 2.5kg bwt Birth weight kilograms age1,age2,age3 Orthogonal polynomials first, second, third degree representing mother's age years lwt1,lwt2,lwt3 Orthogonal polynomials first, second, third degree representing mother's weight pounds last menstrual period white,black Indicator functions mother's race; \"\" reference group smoke smoking status pregnancy ptl1,ptl2m Indicator functions one two previous premature labors, respectively.  previous premature labors reference category. ht History hypertension ui Presence uterine irritability ftv1,ftv2,ftv3m Indicator functions one, two, three physician visits first trimester, respectively.  visits reference category.","code":""},{"path":[]},{"path":"/reference/cv.grpreg.html","id":null,"dir":"Reference","previous_headings":"","what":"Cross-validation for grpreg/grpsurv — cv.grpreg","title":"Cross-validation for grpreg/grpsurv — cv.grpreg","text":"Performs k-fold cross validation penalized regression models grouped covariates grid values regularization parameter lambda.","code":""},{"path":"/reference/cv.grpreg.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cross-validation for grpreg/grpsurv — cv.grpreg","text":"","code":"cv.grpreg(   X,   y,   group = 1:ncol(X),   ...,   nfolds = 10,   seed,   fold,   returnY = FALSE,   trace = FALSE )  cv.grpsurv(   X,   y,   group = 1:ncol(X),   ...,   nfolds = 10,   seed,   fold,   se = c(\"quick\", \"bootstrap\"),   returnY = FALSE,   trace = FALSE )"},{"path":"/reference/cv.grpreg.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cross-validation for grpreg/grpsurv — cv.grpreg","text":"X design matrix, grpreg()/grpsurv(). y response vector (matrix), grpreg()/grpsurv(). group grouping vector, grpreg()/grpsurv(). ... Additional arguments grpreg()/grpsurv(). nfolds number cross-validation folds.  Default 10. seed may set seed random number generator order obtain reproducible results. fold fold observation belongs .  default observations randomly assigned. returnY cv.grpreg()/cv.grpsurv() return fitted values cross-validation folds?  Default FALSE; TRUE, return matrix element row , column j fitted value observation fold observation excluded fit, jth value lambda.  NOTE: cv.grpsurv(), rows Y ordered time study, therefore correspond original order observations pased cv.grpsurv. trace set TRUE, cv.grpreg inform user progress announcing beginning CV fold.  Default FALSE. se cv.grpsurv(), method cross-valiation standard error (CVSE) calculated.  'quick' approach based rough approximation, can calculated less instantly.  'bootstrap' approach accurate, requires additional computing time.","code":""},{"path":"/reference/cv.grpreg.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cross-validation for grpreg/grpsurv — cv.grpreg","text":"object S3 class \"cv.grpreg\" containing: cve error value lambda, averaged across cross-validation folds. cvse estimated standard error associated value cve. lambda sequence regularization parameter values along cross-validation error calculated. fit fitted grpreg object whole data. fold fold assignments cross-validation observation; note cv.grpsurv, terms ordered observations, original observations. min index lambda corresponding lambda.min. lambda.min value lambda minimum cross-validation error. null.dev deviance intercept-model. pe family=\"binomial\", cross-validation prediction error value lambda.","code":""},{"path":"/reference/cv.grpreg.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Cross-validation for grpreg/grpsurv — cv.grpreg","text":"function calls grpreg() grpsurv() nfolds times, time leaving 1/nfolds data.  cross-validation error based deviance; see details. Gaussian Poisson responses, folds chosen according simple random sampling.  binomial responses, numbers outcome class balanced across folds; .e., number outcomes y equal 1 fold, possibly 1 numbers divide evenly.  approach used Cox regression well balance amount censoring cross fold. Cox models, cv.grpsurv uses approach calculating full Cox partial likelihood using cross-validated set linear predictors. approaches cross-validation Cox regression model proposed literature; strengths weaknesses various methods penalized regression Cox model subject current research.  simple approximation standard error provided, although option bootstrap standard error (se='bootstrap') also available. grpreg(), seemingly unrelated regressions/multitask learning can carried setting y matrix, case groups set automatically (see grpreg() details), cross-validation carried respect rows y.  mentioned details , recommended standardize responses prior fitting.","code":""},{"path":[]},{"path":"/reference/cv.grpreg.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Cross-validation for grpreg/grpsurv — cv.grpreg","text":"Patrick Breheny","code":""},{"path":"/reference/cv.grpreg.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Cross-validation for grpreg/grpsurv — cv.grpreg","text":"","code":"data(Birthwt) X <- Birthwt$X y <- Birthwt$bwt group <- Birthwt$group  cvfit <- cv.grpreg(X, y, group) plot(cvfit)  summary(cvfit) #> grLasso-penalized linear regression with n=189, p=16 #> At minimum cross-validation error (lambda=0.0080): #> ------------------------------------------------- #>   Nonzero coefficients: 16 #>   Nonzero groups: 8 #>   Cross-validation error of 0.44 #>   Maximum R-squared: 0.17 #>   Maximum signal-to-noise ratio: 0.20 #>   Scale estimate (sigma) at lambda.min: 0.663 coef(cvfit) ## Beta at minimum CVE #>  (Intercept)         age1         age2         age3         lwt1         lwt2  #>  3.044490766 -0.011903110  1.429405469  0.830865167  1.721770019 -0.001171222  #>         lwt3        white        black        smoke         ptl1        ptl2m  #>  1.252330094  0.277824567 -0.138527669 -0.267472875 -0.277700649  0.193007108  #>           ht           ui         ftv1         ftv2        ftv3m  #> -0.522415974 -0.463194421  0.073062346  0.022384572 -0.126538346   cvfit <- cv.grpreg(X, y, group, penalty=\"gel\") plot(cvfit)  summary(cvfit) #> gel-penalized linear regression with n=189, p=16 #> At minimum cross-validation error (lambda=0.0243): #> ------------------------------------------------- #>   Nonzero coefficients: 15 #>   Nonzero groups: 8 #>   Cross-validation error of 0.45 #>   Maximum R-squared: 0.15 #>   Maximum signal-to-noise ratio: 0.18 #>   Scale estimate (sigma) at lambda.min: 0.669"},{"path":"/reference/expand_spline.html","id":null,"dir":"Reference","previous_headings":"","what":"Expand feature matrix using basis splines — expand_spline","title":"Expand feature matrix using basis splines — expand_spline","text":"Performs basis expansion many features , returning output compatible use grpreg() function. Returns expanded matrix along vector describes grouping.","code":""},{"path":"/reference/expand_spline.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Expand feature matrix using basis splines — expand_spline","text":"","code":"expand_spline(x, df = 3, degree = 3, type = c(\"ns\", \"bs\"))"},{"path":"/reference/expand_spline.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Expand feature matrix using basis splines — expand_spline","text":"x Features expanded (numeric matrix). df Degrees freedom (numeric; default = 3). degree Degree piecewise polynomial (integer; default = 3 (cubic splines)). type Type spline, either B-spline (\"bs\") natural cubic spline (\"ns\"; default).","code":""},{"path":"/reference/expand_spline.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Expand feature matrix using basis splines — expand_spline","text":"object class expandedMatrix consisting : X: matrix dimension nrow(x) df*ncol(x) group: vector length df*ncol(x) describes grouping structure Additional metadata splines, knot locations, required order evaluate spline new feature values (e.g., prediction)","code":""},{"path":"/reference/expand_spline.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Expand feature matrix using basis splines — expand_spline","text":"expand_spline() uses function splines::bs() splines::ns() generate basis matrix column x. matrices represent spline basis piecewise polynomials specified degree evaluated separately original column x. matrices column-bound form single grouped matrix derived features. vector describes grouping present resulting matrix also generated. resulting object can passed grpreg(). methodology originally proposed Ravikumar et al. (2009), named SPAM (SParse Additive Modeling).","code":""},{"path":"/reference/expand_spline.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Expand feature matrix using basis splines — expand_spline","text":"Ravikumar P, Lafferty J, Liu H Wasserman L (2009). Sparse additive models. Journal Royal Statistical Society Series B, 71: 1009-1030.","code":""},{"path":[]},{"path":"/reference/expand_spline.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Expand feature matrix using basis splines — expand_spline","text":"","code":"Data <- gen_nonlinear_data(n=1000) X <- expand_spline(Data$X) fit <- grpreg(X, Data$y) plot_spline(fit, \"V02\", lambda = 0.03)"},{"path":"/reference/gBridge.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit a group bridge regression path — gBridge","title":"Fit a group bridge regression path — gBridge","text":"Fit regularization paths linear logistic group bridge-penalized regression models grid values regularization parameter lambda.","code":""},{"path":"/reference/gBridge.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit a group bridge regression path — gBridge","text":"","code":"gBridge(   X,   y,   group = 1:ncol(X),   family = c(\"gaussian\", \"binomial\", \"poisson\"),   nlambda = 100,   lambda,   lambda.min = {      if (nrow(X) > ncol(X))           0.001      else 0.05  },   lambda.max,   alpha = 1,   eps = 0.001,   delta = 1e-07,   max.iter = 10000,   gamma = 0.5,   group.multiplier,   warn = TRUE,   returnX = FALSE,   ... )"},{"path":"/reference/gBridge.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit a group bridge regression path — gBridge","text":"X design matrix, grpreg. y response vector (matrix), grpreg. group grouping vector, grpreg. family Either \"gaussian\" \"binomial\", depending response. nlambda number lambda values, grpreg. lambda user supplied sequence lambda values, grpreg()`. lambda.min smallest value lambda, grpreg. lambda.max maximum value lambda.  Unlike penalties grpreg, possible solve lambda.max directly group bridge models.  Thus, must specified user.  specified, gBridge attempt guess lambda.max, particularly accurate. alpha Tuning parameter balance group penalty L2 penalty, grpreg. eps Convergence threshhold, grpreg. delta group bridge penalty differentiable zero, requires small number delta bound away zero.  typically need change value. max.iter Maximum number iterations, grpreg. gamma Tuning parameter group bridge penalty (exponent L1 norm coefficients group raised).  Default 0.5, square root. group.multiplier multiplicative factor group's penalty multiplied, grpreg. warn function give warning fails converge?  grpreg. returnX Return standardized design matrix (associated group structure information)?  Default FALSE. ... used.","code":""},{"path":"/reference/gBridge.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fit a group bridge regression path — gBridge","text":"object S3 class \"grpreg\", grpreg.","code":""},{"path":"/reference/gBridge.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Fit a group bridge regression path — gBridge","text":"method fits group bridge method Huang et al. (2009).  Unlike penalties grpreg, group bridge differentiable zero; , number changes must made algorithm, function.  notably, method unable start lambda.max; must start lambda.min proceed opposite direction. respects, usage behavior function similar rest grpreg package.","code":""},{"path":"/reference/gBridge.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Fit a group bridge regression path — gBridge","text":"Huang J, Ma S, Xie H, Zhang C. (2009) group bridge approach variable selection. Biometrika, 96: 339-355. doi:10.1093/biomet/asp020 Breheny P Huang J. (2009) Penalized methods bi-level variable selection. Statistics interface, 2: 369-380. doi:10.4310/sii.2009.v2.n3.a10","code":""},{"path":[]},{"path":"/reference/gBridge.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fit a group bridge regression path — gBridge","text":"","code":"data(Birthwt) X <- Birthwt$X group <- Birthwt$group  ## Linear regression y <- Birthwt$bwt fit <- gBridge(X, y, group, lambda.max=0.08) plot(fit)  select(fit)$beta #> (Intercept)        age1        age2        age3        lwt1        lwt2  #>  2.99879853  0.00000000  0.89267968  0.28165358  1.01904200  0.00000000  #>        lwt3       white       black       smoke        ptl1       ptl2m  #>  0.73440772  0.26506953 -0.04018746 -0.22057682 -0.17180959  0.00000000  #>          ht          ui        ftv1        ftv2       ftv3m  #> -0.28672009 -0.38432026  0.00000000  0.00000000  0.00000000   ## Logistic regression y <- Birthwt$low fit <- gBridge(X, y, group, family=\"binomial\", lambda.max=0.17) plot(fit)  select(fit)$beta #> (Intercept)        age1        age2        age3        lwt1        lwt2  #>  -1.1301892   0.0000000   0.0000000   0.0000000  -5.0796684   0.0000000  #>        lwt3       white       black       smoke        ptl1       ptl2m  #>  -2.3951319  -0.5339085   0.2009164   0.4970655   1.3205915   0.0000000  #>          ht          ui        ftv1        ftv2       ftv3m  #>   1.2699575   0.3267903   0.0000000   0.0000000   0.0000000"},{"path":"/reference/gen_nonlinear_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate nonlinear example data — gen_nonlinear_data","title":"Generate nonlinear example data — gen_nonlinear_data","text":"Mainly intended demonstrate use basis expansion models sparse additive modeling; intended use expand_spline().","code":""},{"path":"/reference/gen_nonlinear_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate nonlinear example data — gen_nonlinear_data","text":"","code":"gen_nonlinear_data(n = 100, p = 16, seed)"},{"path":"/reference/gen_nonlinear_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate nonlinear example data — gen_nonlinear_data","text":"n Sample size (numeric; default = 100). p Number features (numeric; default = 16). seed Set get different random data sets, passed set.seed()","code":""},{"path":"/reference/gen_nonlinear_data.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate nonlinear example data — gen_nonlinear_data","text":"","code":"Data <- gen_nonlinear_data()"},{"path":"/reference/grpreg-package.html","id":null,"dir":"Reference","previous_headings":"","what":"grpreg: Regularization Paths for Regression Models with Grouped Covariates — grpreg-package","title":"grpreg: Regularization Paths for Regression Models with Grouped Covariates — grpreg-package","text":"Efficient algorithms fitting regularization path linear regression, GLM, Cox regression models grouped penalties. includes group selection methods group lasso, group MCP, group SCAD well bi-level selection methods group exponential lasso, composite MCP, group bridge. information, see Breheny Huang (2009) doi:10.4310/sii.2009.v2.n3.a10 , Huang, Breheny, Ma (2012) doi:10.1214/12-sts392 , Breheny Huang (2015) doi:10.1007/s11222-013-9424-2 , Breheny (2015) doi:10.1111/biom.12300 , visit package homepage https://pbreheny.github.io/grpreg/.","code":""},{"path":"/reference/grpreg-package.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"grpreg: Regularization Paths for Regression Models with Grouped Covariates — grpreg-package","text":"Yuan M Lin Y. (2006) Model selection estimation regression grouped variables. Journal Royal Statistical Society Series B, 68: 49-67. doi:10.1111/j.1467-9868.2005.00532.x Huang J, Ma S, Xie H, Zhang C. (2009) group bridge approach variable selection. Biometrika, 96: 339-355. doi:10.1093/biomet/asp020 Breheny P Huang J. (2009) Penalized methods bi-level variable selection. Statistics interface, 2: 369-380. doi:10.4310/sii.2009.v2.n3.a10 Huang J, Breheny P, Ma S. (2012). selective review group selection high dimensional models. Statistical Science, 27: 481-499. doi:10.1214/12-sts392 Breheny P Huang J. (2015) Group descent algorithms nonconvex penalized linear logistic regression models grouped predictors. Statistics Computing, 25: 173-187. doi:10.1007/s11222-013-9424-2 Breheny P. (2015) group exponential lasso bi-level variable selection. Biometrics, 71: 731-740. doi:10.1111/biom.12300","code":""},{"path":[]},{"path":"/reference/grpreg-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"grpreg: Regularization Paths for Regression Models with Grouped Covariates — grpreg-package","text":"Patrick Breheny","code":""},{"path":"/reference/grpreg-package.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"grpreg: Regularization Paths for Regression Models with Grouped Covariates — grpreg-package","text":"","code":"vignette(\"getting-started\", package=\"grpreg\") #> Warning: vignette ‘getting-started’ not found"},{"path":"/reference/grpreg.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit a group penalized regression path — grpreg","title":"Fit a group penalized regression path — grpreg","text":"Fit regularization paths models grouped penalties grid values regularization parameter lambda. Fits linear logistic regression models.","code":""},{"path":"/reference/grpreg.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit a group penalized regression path — grpreg","text":"","code":"grpreg(   X,   y,   group = 1:ncol(X),   penalty = c(\"grLasso\", \"grMCP\", \"grSCAD\", \"gel\", \"cMCP\"),   family = c(\"gaussian\", \"binomial\", \"poisson\"),   nlambda = 100,   lambda,   lambda.min = {      if (nrow(X) > ncol(X))           1e-04      else 0.05  },   log.lambda = TRUE,   alpha = 1,   eps = 1e-04,   max.iter = 10000,   dfmax = p,   gmax = length(unique(group)),   gamma = ifelse(penalty == \"grSCAD\", 4, 3),   tau = 1/3,   group.multiplier,   warn = TRUE,   returnX = FALSE,   ... )"},{"path":"/reference/grpreg.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit a group penalized regression path — grpreg","text":"X design matrix, without intercept.  grpreg standardizes data includes intercept default. y response vector, matrix case multitask learning (see details). group vector describing grouping coefficients.  greatest efficiency least ambiguity (see details), best group factor vector consecutive integers, although unordered groups character vectors also allowed.  coefficients included model without penalized, assign group 0 (\"0\"). penalty penalty applied model.  group selection, one grLasso, grMCP, grSCAD.  bi-level selection, one gel cMCP.  See details. family Either \"gaussian\" \"binomial\", depending response. nlambda number lambda values.  Default 100. lambda user supplied sequence lambda values.  Typically, left unspecified, function automatically computes grid lambda values ranges uniformly log scale relevant range lambda values. lambda.min smallest value lambda, fraction lambda.max.  Default .0001 number observations larger number covariates .05 otherwise. log.lambda Whether compute grid values lambda log scale (default) linear scale. alpha grpreg allows group penalty L2 (ridge) penalty; alpha controls proportional weight regularization parameters two penalties.  group penalties' regularization parameter lambda*alpha, regularization parameter ridge penalty lambda*(1-alpha).  Default 1: ridge penalty. eps Convergence threshhold.  algorithm iterates RMSD change linear predictors coefficient less eps.  Default 1e-4.  See details. max.iter Maximum number iterations (total across entire path). Default 10000.  See details. dfmax Limit number parameters allowed nonzero.  limit exceeded, algorithm exit early regularization path. gmax Limit number groups allowed nonzero elements. limit exceeded, algorithm exit early regularization path. gamma Tuning parameter group composite MCP/SCAD penalty (see details).  Default 3 MCP 4 SCAD. tau Tuning parameter group exponential lasso; defaults 1/3. group.multiplier vector values representing multiplicative factors group's penalty multiplied.  Often, function (square root) number predictors group.  default use square root group size group selection methods, vector 1's (.e., adjustment group size) bi-level selection. warn function give warning fails converge? Default TRUE.  See details. returnX Return standardized design matrix (associated group structure information)?  Default FALSE. ... Arguments passed functions (gBridge).","code":""},{"path":"/reference/grpreg.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fit a group penalized regression path — grpreg","text":"object S3 class \"grpreg\" containing: beta fitted matrix coefficients.  number rows equal number coefficients, number columns equal nlambda. family . group . lambda sequence lambda values path. alpha . deviance vector containing deviance fitted model value lambda. n Number observations. penalty . df vector length nlambda containing estimates effective number model parameters points along regularization path.  details calculated, see Breheny Huang (2009). iter vector length nlambda containing number iterations convergence value lambda. group.multiplier named vector containing multiplicative constant applied group's penalty.","code":""},{"path":"/reference/grpreg.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Fit a group penalized regression path — grpreg","text":"two general classes methods involving grouped penalties: carry bi-level selection carry group selection. Bi-level means carrying variable selection group level well level individual covariates (.e., selecting important groups well important members groups).  Group selection selects important groups, members within group – .e., within group, coefficients either zero nonzero.  grLasso, grMCP, grSCAD penalties carry group selection, gel cMCP penalties carry bi-level selection.  bi-level selection, see also gBridge() function.  historical reasons backwards compatibility, penalties aliases; e.g., gLasso thing grLasso, users encouraged use grLasso. Please note distinction grMCP cMCP.  former involves MCP penalty applied L2-norm group. latter involves hierarchical penalty places outer MCP penalty sum inner MCP penalties group, proposed Breheny & Huang, 2009.  Either penalty may referred \"group MCP\", depending publication.  resolve confusion, Huang et al. (2012) proposed name \"composite MCP\" cMCP penalty. information penalties properties, please consult references , many contain discussion, case studies, simulation studies comparing methods.  use grpreg analysis, please cite appropriate reference. keeping notation original MCP paper, tuning parameter MCP penalty denoted 'gamma'.  Note, however, Breheny Huang (2009), gamma denoted ''. objective function grpreg optimization defined $$Q(\\beta|X, y) = \\frac{1}{n} L(\\beta|X, y) + $$$$ P_\\lambda(\\beta)$$ loss function L negative log-likelihood (half deviance) specified outcome distribution (gaussian/binomial/poisson). details, refer following: Models loss functions Penalties bi-level selection methods, locally approximated coordinate descent algorithm employed.  group selection methods, group descent algorithms employed. algorithms employed grpreg stable generally converge quite rapidly values close solution.  However, especially p large compared n, grpreg may fail converge low values lambda, models nonidentifiable nearly singular. Often, region coefficient path interesting.  default behavior warning user convergence criteria met may distracting cases, can modified warn (convergence can always checked later inspecting value iter). models converging, increasing max.iter may efficient way correct problem.  Consider increasing n.lambda lambda.min addition increasing max.iter. Although grpreg allows groups unordered given arbitary names, recommended specify groups consecutive integers. first reason efficiency: groups order, X must reordered prior fitting, process reversed return coefficients according original order X.  inefficient X large.  second reason ambiguity respect arguments group.multiplier.  consecutive integers, group=3 unambiguously denotes third element group.multiplier. Seemingly unrelated regressions/multitask learning can carried using grpreg passing matrix y.  case, X used separate regressions column y, coefficients grouped across responses.  words, column X form group m members, m number columns y.  multiple Gaussian responses, recommended standardize columns y prior fitting, order apply penalization equally across columns. grpreg requires groups non-overlapping.","code":""},{"path":"/reference/grpreg.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Fit a group penalized regression path — grpreg","text":"Breheny P Huang J. (2009) Penalized methods bi-level variable selection. Statistics interface, 2: 369-380. doi:10.4310/sii.2009.v2.n3.a10 Huang J, Breheny P, Ma S. (2012). selective review group selection high dimensional models. Statistical Science, 27: 481-499. doi:10.1214/12-sts392 Breheny P Huang J. (2015) Group descent algorithms nonconvex penalized linear logistic regression models grouped predictors. Statistics Computing, 25: 173-187. doi:10.1007/s11222-013-9424-2 Breheny P. (2015) group exponential lasso bi-level variable selection. Biometrics, 71: 731-740. doi:10.1111/biom.12300","code":""},{"path":[]},{"path":"/reference/grpreg.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Fit a group penalized regression path — grpreg","text":"Patrick Breheny","code":""},{"path":"/reference/grpreg.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fit a group penalized regression path — grpreg","text":"","code":"# Birthweight data data(Birthwt) X <- Birthwt$X group <- Birthwt$group  # Linear regression y <- Birthwt$bwt fit <- grpreg(X, y, group, penalty=\"grLasso\") plot(fit)  fit <- grpreg(X, y, group, penalty=\"grMCP\") plot(fit)  fit <- grpreg(X, y, group, penalty=\"grSCAD\") plot(fit)  fit <- grpreg(X, y, group, penalty=\"gel\") plot(fit)  fit <- grpreg(X, y, group, penalty=\"cMCP\") plot(fit)  select(fit, \"AIC\") #> $beta #> (Intercept)        age1        age2        age3        lwt1        lwt2  #>  3.03000773  0.00000000  1.14484129  0.57059454  1.30067773  0.00000000  #>        lwt3       white       black       smoke        ptl1       ptl2m  #>  0.90025980  0.29687103 -0.05940071 -0.26940924 -0.23983487  0.01075293  #>          ht          ui        ftv1        ftv2       ftv3m  #> -0.45620940 -0.44477459  0.01632410  0.00000000 -0.02590741  #>  #> $lambda #> [1] 0.03869348 #>  #> $df #> [1] 9.805114 #>  #> $IC #>   [1] 419.9884 415.9171 413.0551 410.1149 405.8256 401.0234 395.6942 390.8250 #>   [9] 385.9994 381.6926 378.2296 375.6049 373.2817 371.5483 370.2815 369.4147 #>  [17] 368.8327 368.4968 368.3677 368.4282 368.5912 368.8236 369.1017 369.4053 #>  [25] 369.7208 370.0378 370.3488 370.6482 370.9327 371.1999 371.4486 371.6783 #>  [33] 371.8892 372.0816 372.2563 372.4144 372.7731 373.3927 374.3380 375.1275 #>  [41] 375.7750 376.3135 376.7658 377.1486 377.4743 377.7527 377.9913 378.1963 #>  [49] 378.3725 378.5237 378.6542 378.7677 378.8665 378.9522 379.0265 379.0914 #>  [57] 379.1481 379.1975 379.2410 379.2792 379.3131 379.3429 379.3690 379.3920 #>  [65] 379.4122 379.4298 379.4451 379.4586 379.4705 379.4810 379.4903 379.4984 #>  [73] 379.4869 379.4947 379.5017 379.5078 379.5132 379.5180 379.5222 379.5261 #>  [81] 379.5295 379.5326 379.5354 379.5379 379.5402 379.5422 379.5440 379.5457 #>  [89] 379.5471 379.5484 379.5496 379.5506 379.5515 379.5523 379.5530 379.5537 #>  [97] 379.5542 379.5547 379.5551 379.5555 #>   # Logistic regression y <- Birthwt$low fit <- grpreg(X, y, group, penalty=\"grLasso\", family=\"binomial\") plot(fit)  fit <- grpreg(X, y, group, penalty=\"grMCP\", family=\"binomial\") plot(fit)  fit <- grpreg(X, y, group, penalty=\"grSCAD\", family=\"binomial\") plot(fit)  fit <- grpreg(X, y, group, penalty=\"gel\", family=\"binomial\") plot(fit)  fit <- grpreg(X, y, group, penalty=\"cMCP\", family=\"binomial\") plot(fit)  select(fit, \"BIC\") #> $beta #> (Intercept)        age1        age2        age3        lwt1        lwt2  #>   -1.194072    0.000000    0.000000    0.000000   -6.940487    0.000000  #>        lwt3       white       black       smoke        ptl1       ptl2m  #>   -3.133163    0.000000    0.000000    0.000000    1.602972    0.000000  #>          ht          ui        ftv1        ftv2       ftv3m  #>    1.806523    0.000000    0.000000    0.000000    0.000000  #>  #> $lambda #> [1] 0.06423099 #>  #> $df #> [1] 4.670807 #>  #> $IC #>   [1] 234.6720 230.0990 230.0000 229.9536 229.9441 229.9598 229.9920 230.0346 #>   [9] 229.2504 229.6901 229.9650 234.2584 234.6746 239.7532 239.9728 242.3188 #>  [17] 242.7281 249.3212 255.2388 261.5262 261.6906 261.8543 265.4466 266.0958 #>  [25] 266.5227 272.5203 272.7270 272.8737 272.9777 273.0514 273.1027 273.1361 #>  [33] 273.1565 273.1643 273.1700 273.1707 273.1707 273.1707 273.1707 273.1707 #>  [41] 273.1707 273.1707 273.1707 273.1707 273.1707 273.1707 273.1707 273.1707 #>  [49] 273.1707 273.1707 273.1707 273.1707 273.1707 273.1707 273.1707 273.1707 #>  [57] 273.1707 273.1707 273.1707 273.1707 273.1707 273.1707 273.1707 273.1707 #>  [65] 273.1707 273.1707 273.1707 273.1707 273.1707 273.1707 273.1707 273.1707 #>  [73] 273.1707 273.1707 273.1707 273.1707 273.1707 273.1707 273.1707 273.1707 #>  [81] 273.1707 273.1707 273.1707 273.1707 273.1707 273.1707 273.1707 273.1707 #>  [89] 273.1707 273.1707 273.1707 273.1707 273.1707 273.1707 273.1707 273.1707 #>  [97] 273.1707 273.1707 273.1707 273.1707 #>   # Multitask learning (simulated example) set.seed(1) n <- 50 p <- 10 k <- 5 X <- matrix(runif(n*p), n, p) y <- matrix(rnorm(n*k, X[,1] + X[,2]), n, k) fit <- grpreg(X, y) # Note that group is set up automatically fit$group #> [1] 5  6  7  8  9  10 #> Levels: 5 6 7 8 9 10 plot(fit)"},{"path":"/reference/grpsurv.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit an group penalized survival model — grpsurv","title":"Fit an group penalized survival model — grpsurv","text":"Fit regularization paths Cox models grouped penalties grid values regularization parameter lambda.","code":""},{"path":"/reference/grpsurv.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit an group penalized survival model — grpsurv","text":"","code":"grpsurv(   X,   y,   group = 1:ncol(X),   penalty = c(\"grLasso\", \"grMCP\", \"grSCAD\", \"gel\", \"cMCP\"),   gamma = ifelse(penalty == \"grSCAD\", 4, 3),   alpha = 1,   nlambda = 100,   lambda,   lambda.min = {      if (nrow(X) > ncol(X))           0.001      else 0.05  },   eps = 0.001,   max.iter = 10000,   dfmax = p,   gmax = length(unique(group)),   tau = 1/3,   group.multiplier,   warn = TRUE,   returnX = FALSE,   ... )"},{"path":"/reference/grpsurv.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit an group penalized survival model — grpsurv","text":"X design matrix. y time--event outcome, two-column matrix Surv object.  first column time study (follow time); second column binary variable 1 indicating event occurred 0 indicating (right) censoring. group vector describing grouping coefficients.  greatest efficiency least ambiguity (see details), best group factor vector consecutive integers, although unordered groups character vectors also allowed.  coefficients included model without penalized, assign group 0 (\"0\"). penalty penalty applied model.  group selection, one grLasso, grMCP, grSCAD.  bi-level selection, one gel cMCP.  See details. gamma Tuning parameter group composite MCP/SCAD penalty (see details).  Default 3 MCP 4 SCAD. alpha grpsurv allows group penalty L2 (ridge) penalty; alpha controls proportional weight regularization parameters two penalties.  group penalties' regularization parameter lambda*alpha, regularization parameter ridge penalty lambda*(1-alpha).  Default 1: ridge penalty. nlambda number lambda values.  Default 100. lambda user-specified sequence lambda values.  default, sequence values length nlambda computed automatically, equally spaced log scale. lambda.min smallest value lambda, fraction lambda.max.  Default .001 number observations larger number covariates .05 otherwise. eps Convergence threshhold.  algorithm iterates RMSD change linear predictors coefficient less eps.  Default 0.001. max.iter Maximum number iterations (total across entire path). Default 10000. dfmax Limit number parameters allowed nonzero.  limit exceeded, algorithm exit early regularization path. gmax Limit number groups allowed nonzero elements. limit exceeded, algorithm exit early regularization path. tau Tuning parameter group exponential lasso; defaults 1/3. group.multiplier vector values representing multiplicative factors group's penalty multiplied.  Often, function (square root) number predictors group.  default use square root group size group selection methods, vector 1's (.e., adjustment group size) bi-level selection. warn Return warning messages failures converge model saturation?  Default TRUE. returnX Return standardized design matrix?  Default FALSE. ... used.","code":""},{"path":"/reference/grpsurv.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fit an group penalized survival model — grpsurv","text":"object S3 class \"grpsurv\" containing: beta fitted matrix coefficients. number rows equal number coefficients, number columns equal nlambda. group . lambda sequence lambda values path. penalty . gamma . alpha . deviance deviance fitted model value lambda. n number observations. df vector length nlambda containing estimates effective number model parameters points along regularization path. details calculated, see Breheny Huang (2009). iter vector length nlambda containing number iterations convergence value lambda. group.multiplier named vector containing multiplicative constant applied group's penalty. Cox models, following objects also returned (necessary estimate baseline survival conditional estimated regression coefficients), ordered time study (.e., ith row W correspond ith row X): W Matrix exp(beta) values subject lambda values. time Times study. fail Failure event indicator.","code":""},{"path":"/reference/grpsurv.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Fit an group penalized survival model — grpsurv","text":"sequence models indexed regularization parameter lambda fit using coordinate descent algorithm.  order accomplish , second derivative (Hessian) Cox partial log-likelihood diagonalized (see references details).  objective function defined $$Q(\\beta|X, y) = \\frac{1}{n} L(\\beta|X, y) + $$$$ P_\\lambda(\\beta)$$ loss function L negative partial log-likelihood (half deviance) Cox regression model. See details. Presently, ties handled grpsurv particularly sophisticated manner.  improved upon future release grpreg.","code":""},{"path":"/reference/grpsurv.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Fit an group penalized survival model — grpsurv","text":"Breheny P Huang J. (2009) Penalized methods bi-level variable selection. Statistics interface, 2: 369-380. doi:10.4310/sii.2009.v2.n3.a10 Huang J, Breheny P, Ma S. (2012). selective review group selection high dimensional models. Statistical Science, 27: 481-499. doi:10.1214/12-sts392 Breheny P Huang J. (2015) Group descent algorithms nonconvex penalized linear logistic regression models grouped predictors. Statistics Computing, 25: 173-187. doi:10.1007/s11222-013-9424-2 Breheny P. (2015) group exponential lasso bi-level variable selection. Biometrics, 71: 731-740. doi:10.1111/biom.12300 Simon N, Friedman JH, Hastie T, Tibshirani R. (2011) Regularization Paths Cox's Proportional Hazards Model via Coordinate Descent. Journal Statistical Software, 39: 1-13. doi:10.18637/jss.v039.i05","code":""},{"path":[]},{"path":"/reference/grpsurv.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Fit an group penalized survival model — grpsurv","text":"Patrick Breheny","code":""},{"path":"/reference/grpsurv.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fit an group penalized survival model — grpsurv","text":"","code":"data(Lung) X <- Lung$X y <- Lung$y group <- Lung$group  fit <- grpsurv(X, y, group) plot(fit)   S <- predict(fit, X, type='survival', lambda=0.05) plot(S, xlim=c(0,200))"},{"path":"/reference/logLik.grpreg.html","id":null,"dir":"Reference","previous_headings":"","what":"logLik method for grpreg — logLik.grpreg","title":"logLik method for grpreg — logLik.grpreg","text":"Calculates log likelihood degrees freedom fitted grpreg object.","code":""},{"path":"/reference/logLik.grpreg.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"logLik method for grpreg — logLik.grpreg","text":"","code":"# S3 method for class 'grpreg' logLik(object, df.method = c(\"default\", \"active\"), REML = FALSE, ...)  # S3 method for class 'grpsurv' logLik(object, df.method = c(\"default\", \"active\"), ...)"},{"path":"/reference/logLik.grpreg.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"logLik method for grpreg — logLik.grpreg","text":"object fitted grpreg grpsurv object, obtained grpreg() grpsurv() df.method effective model parameters calculated? One : \"active\", counts number nonzero coefficients; \"default\", uses calculated df returned grpreg. Default \"default\". REML Use restricted MLE estimation scale parameter gaussian model?  Default FALSE. ... S3 method compatibility.","code":""},{"path":"/reference/logLik.grpreg.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"logLik method for grpreg — logLik.grpreg","text":"Returns object class 'logLik', case consisting number (vector numbers) two attributes: 'df' (estimated degrees freedom model) 'nobs' (number observations). 'print' method 'logLik' objects intended handle vectors; consequently, value function necessarily display correctly.  However, works 'AIC' 'BIC' without glitches returns expected vectorized output.","code":""},{"path":"/reference/logLik.grpreg.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"logLik method for grpreg — logLik.grpreg","text":"Exists mainly use stats::AIC() stats::BIC().","code":""},{"path":[]},{"path":"/reference/logLik.grpreg.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"logLik method for grpreg — logLik.grpreg","text":"Patrick Breheny","code":""},{"path":"/reference/logLik.grpreg.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"logLik method for grpreg — logLik.grpreg","text":"","code":"data(Birthwt) X <- Birthwt$X y <- Birthwt$bwt group <- Birthwt$group fit <- grpreg(X,y,group,penalty=\"cMCP\") logLik(fit) ## Display is glitchy for vectors #> 'log Lik.' -207.9942, -205.8047, -204.2471, -202.6167, -200.1960, -197.4306, -194.3174, -191.4073, -188.4177, -185.6547, -183.3583, -181.5515, -179.8315, -178.4712, -177.4033, -176.4566, -175.7113, -175.0176, -174.3787, -173.8237, -173.3874, -173.0445, -172.7754, -172.5640, -172.3983, -172.2685, -172.1669, -172.0874, -172.0254, -171.9770, -171.9392, -171.9098, -171.8870, -171.8693, -171.8555, -171.8449, -171.8355, -171.8255, -171.8150, -171.8067, -171.8003, -171.7954, -171.7915, -171.7886, -171.7863, -171.7845, -171.7832, -171.7821, -171.7813, -171.7807, -171.7803, -171.7799, -171.7796, -171.7794, -171.7793, -171.7791, -171.7791, -171.7790, -171.7789, -171.7789, -171.7789, -171.7788, -171.7788, -171.7788, -171.7788, -171.7788, -171.7788, -171.7788, -171.7788, -171.7788, -171.7788, -171.7788, -171.7788, -171.7788, -171.7788, -171.7788, -171.7788, -171.7788, -171.7788, -171.7788, -171.7788, -171.7788, -171.7788, -171.7788, -171.7788, -171.7788, -171.7788, -171.7788, -171.7788, -171.7788, -171.7788, -171.7788, -171.7788, -171.7788, -171.7788, -171.7788, -171.7788, -171.7788, -171.7788, -171.7788 (df= 2.000000 2.153895 2.280447 2.440723 2.716807 3.081085 3.529672 4.005194 4.582002 5.191650 5.756456 6.250947 6.809371 7.302987 7.737498 8.250717 8.705069 9.230792 9.80511410.39037110.90821011.36729411.77549612.13863512.46211712.75044513.00750313.23668113.44096113.62297813.78506913.92931914.05758914.17154614.27263214.36230014.55110014.87085515.35404915.75704316.08718916.36138716.59137016.78570516.95085517.09181017.21249417.31603517.40488917.48113417.54683817.60396717.65360717.69669117.73398417.76657317.79501717.81979017.84159517.86071417.87767917.89259817.90570817.91721417.92729517.93611217.94376717.95052417.95648517.96173717.96636017.97042517.96469917.96860017.97208917.97515217.97783917.98022117.98235217.98427217.98600017.98755517.98895217.99020817.99133517.99234717.99325317.99406417.99478917.99543617.99601417.99652817.99698517.99739117.99775117.99806817.99834817.99859417.99881017.998999) AIC(fit) #>   [1] 419.9884 415.9171 413.0551 410.1149 405.8256 401.0234 395.6942 390.8250 #>   [9] 385.9994 381.6926 378.2296 375.6049 373.2817 371.5483 370.2815 369.4147 #>  [17] 368.8327 368.4968 368.3677 368.4282 368.5912 368.8236 369.1017 369.4053 #>  [25] 369.7208 370.0378 370.3488 370.6482 370.9327 371.1999 371.4486 371.6783 #>  [33] 371.8892 372.0816 372.2563 372.4144 372.7731 373.3927 374.3380 375.1275 #>  [41] 375.7750 376.3135 376.7658 377.1486 377.4743 377.7527 377.9913 378.1963 #>  [49] 378.3725 378.5237 378.6542 378.7677 378.8665 378.9522 379.0265 379.0914 #>  [57] 379.1481 379.1975 379.2410 379.2792 379.3131 379.3429 379.3690 379.3920 #>  [65] 379.4122 379.4298 379.4451 379.4586 379.4705 379.4810 379.4903 379.4984 #>  [73] 379.4869 379.4947 379.5017 379.5078 379.5132 379.5180 379.5222 379.5261 #>  [81] 379.5295 379.5326 379.5354 379.5379 379.5402 379.5422 379.5440 379.5457 #>  [89] 379.5471 379.5484 379.5496 379.5506 379.5515 379.5523 379.5530 379.5537 #>  [97] 379.5542 379.5547 379.5551 379.5555 BIC(fit) #>   [1] 426.4719 422.8995 420.4477 418.0271 414.6328 411.0115 407.1365 403.8089 #>   [9] 400.8531 398.5227 396.8905 395.8689 395.3560 395.2227 395.3646 396.1615 #>  [17] 397.0523 398.4207 400.1534 402.1112 403.9529 405.6735 407.2749 408.7556 #>  [25] 410.1198 411.3716 412.5158 413.5582 414.5049 415.3621 416.1363 416.8336 #>  [33] 417.4603 418.0222 418.5246 418.9733 419.9441 421.6002 424.1120 426.2079 #>  [41] 427.9256 429.3530 430.5508 431.5636 432.4247 433.1600 433.7899 434.3306 #>  [49] 434.7947 435.1931 435.5366 435.8354 436.0950 436.3204 436.5156 436.6862 #>  [57] 436.8351 436.9648 437.0790 437.1791 437.2680 437.3461 437.4148 437.4751 #>  [65] 437.5279 437.5741 437.6142 437.6497 437.6809 437.7084 437.7326 437.7540 #>  [73] 437.7240 437.7444 437.7627 437.7787 437.7928 437.8053 437.8165 437.8265 #>  [81] 437.8356 437.8437 437.8511 437.8576 437.8636 437.8689 437.8736 437.8779 #>  [89] 437.8817 437.8850 437.8881 437.8908 437.8932 437.8953 437.8972 437.8988 #>  [97] 437.9003 437.9016 437.9027 437.9037"},{"path":"/reference/plot.cv.grpreg.html","id":null,"dir":"Reference","previous_headings":"","what":"Plots the cross-validation curve from a cv.grpreg object — plot.cv.grpreg","title":"Plots the cross-validation curve from a cv.grpreg object — plot.cv.grpreg","text":"Plots cross-validation curve cv.grpreg object, along standard error bars.","code":""},{"path":"/reference/plot.cv.grpreg.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plots the cross-validation curve from a cv.grpreg object — plot.cv.grpreg","text":"","code":"# S3 method for class 'cv.grpreg' plot(   x,   log.l = TRUE,   type = c(\"cve\", \"rsq\", \"scale\", \"snr\", \"pred\", \"all\"),   selected = TRUE,   vertical.line = TRUE,   col = \"red\",   ... )"},{"path":"/reference/plot.cv.grpreg.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plots the cross-validation curve from a cv.grpreg object — plot.cv.grpreg","text":"x cv.grpreg object. log.l horizontal axis log scale?  Default TRUE. type plot vertical axis.  cve plots cross-validation error (deviance); rsq plots estimate fraction deviance explained model (R-squared); snr plots estimate signal--noise ratio; scale plots, family=\"gaussian\", estimate scale parameter (standard deviation); pred plots, family=\"binomial\", estimated prediction error; produces . selected TRUE (default), places axis top plot denoting number groups model (.e., contain nonzero regression coefficient) value lambda. vertical.line TRUE (default), draws vertical line value cross-validaton error minimized. col Controls color dots (CV estimates). ... graphical parameters plot","code":""},{"path":"/reference/plot.cv.grpreg.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Plots the cross-validation curve from a cv.grpreg object — plot.cv.grpreg","text":"Error bars representing approximate +/- 1 SE (68\\ plotted along estimates value lambda.  rsq snr, confidence intervals quite crude, especially near zero, hopefully improved upon later versions grpreg.","code":""},{"path":[]},{"path":"/reference/plot.cv.grpreg.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plots the cross-validation curve from a cv.grpreg object — plot.cv.grpreg","text":"","code":"# Birthweight data data(Birthwt) X <- Birthwt$X group <- Birthwt$group  # Linear regression y <- Birthwt$bwt cvfit <- cv.grpreg(X, y, group) plot(cvfit) op <- par(mfrow=c(2,2)) plot(cvfit, type=\"all\")   ## Logistic regression y <- Birthwt$low cvfit <- cv.grpreg(X, y, group, family=\"binomial\") par(op) plot(cvfit) par(mfrow=c(2,2)) plot(cvfit, type=\"all\")"},{"path":"/reference/plot.grpreg.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot coefficients from a ","title":"Plot coefficients from a ","text":"Produces plot coefficient paths fitted grpreg object.","code":""},{"path":"/reference/plot.grpreg.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot coefficients from a ","text":"","code":"# S3 method for class 'grpreg' plot(x, alpha = 1, legend.loc, label = FALSE, log.l = FALSE, norm = FALSE, ...)"},{"path":"/reference/plot.grpreg.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot coefficients from a ","text":"x Fitted \"grpreg\" model. alpha Controls alpha-blending.  Default alpha=1. legend.loc legend go?  left unspecified, legend drawn.  See legend details. label TRUE, annotates plot text labels right margin describing variable/group corresponding line belongs . log.l horizontal axis log scale?  Default FALSE. norm TRUE, plot norm group, rather individual coefficients. ... graphical parameters plot, matlines, legend","code":""},{"path":[]},{"path":"/reference/plot.grpreg.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot coefficients from a ","text":"","code":"# Fit model to birthweight data data(Birthwt) X <- Birthwt$X y <- Birthwt$bwt group <- Birthwt$group fit <- grpreg(X, y, group, penalty=\"grLasso\")  # Plot (basic) plot(fit)   # Plot group norms, with labels in right margin plot(fit, norm=TRUE, label=TRUE)   # Plot (miscellaneous options) myColors <- c(\"black\", \"red\", \"green\", \"blue\", \"yellow\", \"purple\", \"orange\", \"brown\") plot(fit, legend.loc=\"topleft\", col=myColors)  labs <- c(\"Mother's Age\", \"# Phys. visits\", \"Hypertension\", \"Mother's weight\",           \"# Premature\", \"Race\", \"Smoking\", \"Uterine irritability\") plot(fit, legend.loc=\"topleft\", lwd=6, alpha=0.5, legend=labs)  plot(fit, norm=TRUE, legend.loc=\"topleft\", lwd=6, alpha=0.5, legend=labs)"},{"path":"/reference/plot.grpsurv.func.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot survival curve for grpsurv model — plot.grpsurv.func","title":"Plot survival curve for grpsurv model — plot.grpsurv.func","text":"Plot survival curve model fit using grpsurv followed prediction survival function using predict.grpsurv","code":""},{"path":"/reference/plot.grpsurv.func.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot survival curve for grpsurv model — plot.grpsurv.func","text":"","code":"# S3 method for class 'grpsurv.func' plot(x, alpha = 1, ...)"},{"path":"/reference/plot.grpsurv.func.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot survival curve for grpsurv model — plot.grpsurv.func","text":"x 'grpsurv.func' object, returned predict.grpsurv type='survival' specified.  See examples. alpha Controls alpha-blending (.e., transparency).  Useful many overlapping lines present. ... graphical parameters pass plot","code":""},{"path":[]},{"path":"/reference/plot.grpsurv.func.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Plot survival curve for grpsurv model — plot.grpsurv.func","text":"Patrick Breheny","code":""},{"path":"/reference/plot.grpsurv.func.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot survival curve for grpsurv model — plot.grpsurv.func","text":"","code":"data(Lung) X <- Lung$X y <- Lung$y group <- Lung$group fit <- grpsurv(X, y, group)  # A single survival curve S <- predict(fit, X[1,], type='survival', lambda=.05) plot(S, xlim=c(0,200))   # Lots of survival curves S <- predict(fit, X, type='survival', lambda=.05) plot(S, xlim=c(0,200), alpha=0.3)"},{"path":"/reference/plot_spline.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot spline curve for a fitted additive model — plot_spline","title":"Plot spline curve for a fitted additive model — plot_spline","text":"Plots spline curve single variable using grpreg cv.grpreg object additive model fit.","code":""},{"path":"/reference/plot_spline.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot spline curve for a fitted additive model — plot_spline","text":"","code":"plot_spline(   fit,   variable,   lambda,   which = NULL,   partial = FALSE,   type = \"contrast\",   warnings = TRUE,   points.par = NULL,   add = FALSE,   ... )"},{"path":"/reference/plot_spline.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot spline curve for a fitted additive model — plot_spline","text":"fit grpreg object. model must fit using expand_spline object. variable name variable plotted (character). lambda Values regularization parameter lambda used plot. vector passed, curve drawn value lambda (numeric vector; cv.grpreg object passed, lambda value minimizing cross-validation error used default; otherwise, default value) Index penalty parameter lambda used plot. lambda specified, lambda takes precedence (integer vector). partial TRUE, scatter plot partial residuals superimposed curve (logical; default = FALSE). multiple lambdas specified, largest value used calculate residuals. type Type plot produced (default = \"contrast\"). following options supported: \"conditional\", plot returned shows value variable x-axis change linear predictor y-axis, holding variables constant mean value. \"contrast\", plot returned shows effect linear predictor moving x variable away mean. warnings FALSE, warnings suppressed (default = TRUE). points.par List parameters (see par() pass points() partial=TRUE. add Add spline existing plot? (default: FALSE) ... arguments passed plot(). Note arguments also control appearance lines.","code":""},{"path":"/reference/plot_spline.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Plot spline curve for a fitted additive model — plot_spline","text":"plot_spline() takes model fit using grpreg() expand_spline() functions plots spline curve given variable.","code":""},{"path":"/reference/plot_spline.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot spline curve for a fitted additive model — plot_spline","text":"","code":"Data <- gen_nonlinear_data(n=1000) X <- expand_spline(Data$X) fit <- grpreg(X, Data$y) plot_spline(fit, \"V02\", lambda = 0.03)  plot_spline(fit, \"V02\", which = c(10, 90))  plot_spline(fit, \"V02\", lambda = 0.03, partial=TRUE)  plot_spline(fit, \"V02\", lambda = 0.03, partial=TRUE, type='conditional')  plot_spline(fit, \"V02\", lambda = 0.03, partial=TRUE, lwd=6, col='yellow',             points.par=list(pch=9, col='blue'))   op <- par(mfrow=c(3,2), mar=c(4.5, 4.5, 0.25, 0.25)) for (i in 1:6) plot_spline(fit, sprintf(\"V%02d\", i), lambda = 0.03, partial=TRUE)  par(op)  cvfit <- cv.grpreg(X, Data$y) plot_spline(cvfit, \"V02\")  plot_spline(cvfit, \"V02\", partial=TRUE)"},{"path":"/reference/predict.grpreg.html","id":null,"dir":"Reference","previous_headings":"","what":"Model predictions based on a fitted grpreg object — predict.cv.grpreg","title":"Model predictions based on a fitted grpreg object — predict.cv.grpreg","text":"Similar predict methods, function returns predictions fitted \"grpreg\" object.","code":""},{"path":"/reference/predict.grpreg.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Model predictions based on a fitted grpreg object — predict.cv.grpreg","text":"","code":"# S3 method for class 'cv.grpreg' predict(   object,   X,   lambda = object$lambda.min,   which = object$min,   type = c(\"link\", \"response\", \"class\", \"coefficients\", \"vars\", \"groups\", \"nvars\",     \"ngroups\", \"norm\"),   ... )  # S3 method for class 'cv.grpreg' coef(object, lambda = object$lambda.min, which = object$min, ...)  # S3 method for class 'grpreg' predict(   object,   X,   type = c(\"link\", \"response\", \"class\", \"coefficients\", \"vars\", \"groups\", \"nvars\",     \"ngroups\", \"norm\"),   lambda,   which = 1:length(object$lambda),   ... )  # S3 method for class 'grpreg' coef(object, lambda, which = 1:length(object$lambda), drop = TRUE, ...)"},{"path":"/reference/predict.grpreg.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Model predictions based on a fitted grpreg object — predict.cv.grpreg","text":"object Fitted \"grpreg\" \"cv.grpreg\" model object. X Matrix values predictions made.  used type=\"coefficients\" lambda Values regularization parameter lambda predictions requested.  values lambda sequence fitted models, linear interpolation used. Indices penalty parameter lambda predictions required.  default, indices returned.  lambda specified, override . type Type prediction: \"link\" returns linear predictors; \"response\" gives fitted values; \"class\" returns binomial outcome highest probability; \"coefficients\" returns coefficients; \"vars\" returns indices nonzero coefficients; \"groups\" returns indices groups least one nonzero coefficient; \"nvars\" returns number nonzero coefficients; \"ngroups\" returns number groups least one nonzero coefficient; \"norm\" returns L2 norm coefficients group. ... used. drop default, single value lambda supplied, vector coefficients returned.  Set drop=FALSE wish coef always return matrix (see drop).","code":""},{"path":"/reference/predict.grpreg.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Model predictions based on a fitted grpreg object — predict.cv.grpreg","text":"object returned depends type.","code":""},{"path":"/reference/predict.grpreg.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Model predictions based on a fitted grpreg object — predict.cv.grpreg","text":"coef predict methods provided \"cv.grpreg\" options convenience.  simply call coef.grpreg predict.grpreg lambda set value minimizes cross-validation error.","code":""},{"path":[]},{"path":"/reference/predict.grpreg.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Model predictions based on a fitted grpreg object — predict.cv.grpreg","text":"Patrick Breheny","code":""},{"path":"/reference/predict.grpreg.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Model predictions based on a fitted grpreg object — predict.cv.grpreg","text":"","code":"# Fit penalized logistic regression model to birthweight data data(Birthwt) X <- Birthwt$X y <- Birthwt$low group <- Birthwt$group fit <- grpreg(X, y, group, penalty=\"grLasso\", family=\"binomial\")  # Coef and predict methods coef(fit, lambda=.001) #> (Intercept)        age1        age2        age3        lwt1        lwt2  #>  -1.5594452 -11.3887695 -18.3241083 -13.5534407  -6.7400536  -2.0424956  #>        lwt3       white       black       smoke        ptl1       ptl2m  #>  -4.4466007  -0.6955048   0.5156693   0.8198631   1.6532574  -0.2816916  #>          ht          ui        ftv1        ftv2       ftv3m  #>   2.0050588   0.7726613  -0.3866688  -0.1593881   0.6674573  predict(fit, X, type=\"link\", lambda=.07)[1:10] #>  [1] -0.8193011 -0.8702524 -0.8639390 -0.8129877 -0.8129877 -0.8702524 #>  [7] -0.8702524 -0.8702524 -0.8639390 -0.8639390 predict(fit, X, type=\"response\", lambda=.07)[1:10] #>  [1] 0.3059120 0.2952018 0.2965170 0.3072542 0.3072542 0.2952018 0.2952018 #>  [8] 0.2952018 0.2965170 0.2965170 predict(fit, X, type=\"class\", lambda=.01)[1:15] #>  [1] 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 predict(fit, type=\"vars\", lambda=.07) #> smoke  ptl1 ptl2m    ht    ui  #>     9    10    11    12    13  predict(fit, type=\"groups\", lambda=.07) #> [1] smoke ptl   ht    ui    #> Levels: age lwt race smoke ptl ht ui ftv predict(fit, type=\"norm\", lambda=.07) #>         age         lwt        race       smoke         ptl          ht  #> 0.000000000 0.000000000 0.000000000 0.006313417 0.487194445 0.032052407  #>          ui         ftv  #> 0.050951339 0.000000000   # Coef and predict methods for cross-validation cvfit <- cv.grpreg(X, y, group, family=\"binomial\", penalty=\"grMCP\") coef(cvfit) #> (Intercept)        age1        age2        age3        lwt1        lwt2  #> -0.99567389  0.00000000  0.00000000  0.00000000  0.00000000  0.00000000  #>        lwt3       white       black       smoke        ptl1       ptl2m  #>  0.00000000  0.00000000  0.00000000  0.02697791  0.94778608  0.14979714  #>          ht          ui        ftv1        ftv2       ftv3m  #>  0.30980476  0.22330875  0.00000000  0.00000000  0.00000000  predict(cvfit, X)[1:10] #>  [1] -0.7723651 -0.9956739 -0.9686960 -0.7453872 -0.7453872 -0.9956739 #>  [7] -0.9956739 -0.9956739 -0.9686960 -0.9686960 predict(cvfit, X, type=\"response\")[1:10] #>  [1] 0.3159677 0.2697928 0.2751405 0.3218272 0.3218272 0.2697928 0.2697928 #>  [8] 0.2697928 0.2751405 0.2751405 predict(cvfit, type=\"groups\") #> [1] smoke ptl   ht    ui    #> Levels: age lwt race smoke ptl ht ui ftv"},{"path":"/reference/predict.grpsurv.html","id":null,"dir":"Reference","previous_headings":"","what":"Model predictions for grpsurv objects — predict.grpsurv","title":"Model predictions for grpsurv objects — predict.grpsurv","text":"Similar predict methods, function returns predictions fitted grpsurv object.","code":""},{"path":"/reference/predict.grpsurv.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Model predictions for grpsurv objects — predict.grpsurv","text":"","code":"# S3 method for class 'grpsurv' predict(   object,   X,   type = c(\"link\", \"response\", \"survival\", \"hazard\", \"median\", \"norm\", \"coefficients\",     \"vars\", \"nvars\", \"groups\", \"ngroups\"),   lambda,   which = 1:length(object$lambda),   ... )"},{"path":"/reference/predict.grpsurv.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Model predictions for grpsurv objects — predict.grpsurv","text":"object Fitted grpsurv model object. X Matrix values predictions made. required type values. type Type prediction: link: linear predictors response: risk (.e., exp(link)) survival: estimated survival function hazard: estimated cumulative hazard function median: median survival time options identical grpreg() counterparts lambda Regularization parameter predictions requested. values lambda sequence fitted models, linear interpolation used. Indices penalty parameter lambda predictions required. Default: indices. lambda specified, override . ... used.","code":""},{"path":"/reference/predict.grpsurv.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Model predictions for grpsurv objects — predict.grpsurv","text":"object returned depends type.","code":""},{"path":"/reference/predict.grpsurv.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Model predictions for grpsurv objects — predict.grpsurv","text":"Estimation baseline survival function conditional estimated values beta carried according method described Chapter 4.3 Kalbfleisch Prentice.","code":""},{"path":"/reference/predict.grpsurv.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Model predictions for grpsurv objects — predict.grpsurv","text":"Kalbfleish JD Prentice RL (2002). Statistical Analysis Failure Time Data, 2nd edition. Wiley.","code":""},{"path":[]},{"path":"/reference/predict.grpsurv.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Model predictions for grpsurv objects — predict.grpsurv","text":"Patrick Breheny","code":""},{"path":"/reference/predict.grpsurv.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Model predictions for grpsurv objects — predict.grpsurv","text":"","code":"data(Lung) X <- Lung$X  y <- Lung$y group <- Lung$group   fit <- grpsurv(X, y, group) coef(fit, lambda=0.05) #>         trt      karno1      karno2      karno3   diagtime1   diagtime2  #>  0.08037515 -6.17591904  0.78016422 -0.46524844  0.00000000  0.00000000  #>        age1        age2        age3       prior    squamous       small  #> -0.30698476  0.28311172 -0.98219083  0.00000000 -0.39419164  0.17559226  #>       adeno       large  #>  0.41116562 -0.18990837  head(predict(fit, X, type=\"link\", lambda=0.05)) #>          1          2          3          4          5          6  #> -0.3797934 -0.5934333 -0.2596129 -0.3895304 -0.5881482  0.7865260  head(predict(fit, X, type=\"response\", lambda=0.05)) #>         1         2         3         4         5         6  #> 0.6840027 0.5524274 0.7713501 0.6773749 0.5553547 2.1957550    # Survival function S <- predict(fit, X[1,], type=\"survival\", lambda=0.05) S(100) #> [1] 0.5126102 S <- predict(fit, X, type=\"survival\", lambda=0.05) plot(S, xlim=c(0,200))    # Medians predict(fit, X[1,], type=\"median\", lambda=0.05) #> [1] 105 M <- predict(fit, X, type=\"median\") M[1:10, 1:10] #>       [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] #>  [1,]   80   80   80   73   80   80   84   87   90    92 #>  [2,]   80   80   80   82   84   90   95   95   99   100 #>  [3,]   80   80   80   73   80   80   84   87   90    92 #>  [4,]   80   80   80   73   80   80   84   87   90    92 #>  [5,]   80   80   80   82   84   90   95   95   99   100 #>  [6,]   80   61   54   52   51   48   45   43   42    36 #>  [7,]   80   72   61   59   56   56   56   56   56    56 #>  [8,]   80   82   87   90   95   99  103  110  111   112 #>  [9,]   80   73   72   63   63   72   72   73   80    80 #> [10,]   80   80   80   82   84   90   95   95   99   100   # Nonzero coefficients predict(fit, type=\"vars\", lambda=c(0.1, 0.01)) #> $`0.1` #>   karno1   karno2   karno3 squamous    small    adeno    large  #>        2        3        4       11       12       13       14  #>  #> $`0.01` #>       trt    karno1    karno2    karno3 diagtime1 diagtime2      age1      age2  #>         1         2         3         4         5         6         7         8  #>      age3     prior  squamous     small     adeno     large  #>         9        10        11        12        13        14  #>  predict(fit, type=\"nvars\", lambda=c(0.1, 0.01)) #>  0.1 0.01  #>    7   14"},{"path":"/reference/residuals.grpreg.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract residuals from a grpreg or grpsurv fit — residuals.grpreg","title":"Extract residuals from a grpreg or grpsurv fit — residuals.grpreg","text":"Currently, deviance residuals supported.","code":""},{"path":"/reference/residuals.grpreg.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract residuals from a grpreg or grpsurv fit — residuals.grpreg","text":"","code":"# S3 method for class 'grpreg' residuals(object, lambda, which = 1:length(object$lambda), drop = TRUE, ...)"},{"path":"/reference/residuals.grpreg.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract residuals from a grpreg or grpsurv fit — residuals.grpreg","text":"object Object class grpreg grpsurv. lambda Values regularization parameter residuals requested (numeric vector). values lambda sequence fitted models, linear interpolation used. Index penalty parameter residuals requested (default = indices). lambda specified, take precedence . drop default, single value lambda supplied, vector residuals returned (logical; default=TRUE). Set drop=FALSE wish function always return matrix (see drop()). ... used.","code":""},{"path":"/reference/residuals.grpreg.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract residuals from a grpreg or grpsurv fit — residuals.grpreg","text":"","code":"data(Birthwt) X <- Birthwt$X y <- Birthwt$bwt group <- Birthwt$group fit <- grpreg(X, y, group, returnX=TRUE) residuals(fit)[1:5, 1:5] #>          0.2065     0.1882    0.1714     0.1562     0.1423 #> [1,] -0.4215873 -0.3775988 -0.337518 -0.3009980 -0.2677223 #> [2,] -0.3935873 -0.4012375 -0.408208 -0.4145594 -0.4203464 #> [3,] -0.3875873 -0.3952375 -0.402208 -0.4085594 -0.4143464 #> [4,] -0.3505873 -0.3065988 -0.266518 -0.2299980 -0.1967223 #> [5,] -0.3445873 -0.3005988 -0.260518 -0.2239980 -0.1907223 head(residuals(fit, lambda=0.1)) #> [1] -0.17267168 -0.45110465 -0.41799818 -0.08848411 -0.08248411 -0.38010465"},{"path":"/reference/select.html","id":null,"dir":"Reference","previous_headings":"","what":"Select an value of lambda along a grpreg path — select","title":"Select an value of lambda along a grpreg path — select","text":"Selects point along regularization path fitted grpreg object according AIC, BIC, GCV criteria.","code":""},{"path":"/reference/select.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Select an value of lambda along a grpreg path — select","text":"","code":"select(obj, ...)  # S3 method for class 'grpreg' select(   obj,   criterion = c(\"BIC\", \"AIC\", \"GCV\", \"AICc\", \"EBIC\"),   df.method = c(\"default\", \"active\"),   smooth = FALSE,   ... )"},{"path":"/reference/select.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Select an value of lambda along a grpreg path — select","text":"obj fitted grpreg object. ... S3 method compatibility. criterion criterion select regularization parameter.  One \"AIC\", \"BIC\", \"GCV\", \"AICc\", \"EBIC\"; default \"BIC\". df.method effective model parameters calculated?  One : \"active\", counts number nonzero coefficients; \"default\", uses calculated df returned grpreg.  Default \"default\". smooth Applies smoother information criteria selecting optimal value.","code":""},{"path":"/reference/select.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Select an value of lambda along a grpreg path — select","text":"list containing: lambda selected value regularization parameter, lambda. beta vector coefficients chosen value lambda. df effective number model parameters chosen value lambda. IC vector calculated model selection criteria point regularization path.","code":""},{"path":"/reference/select.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Select an value of lambda along a grpreg path — select","text":"criteria defined follows, \\(L\\) deviance (.e, -2 times log-likelihood), \\(\\nu\\) degrees freedom, \\(n\\) sample size: $$AIC = L + 2\\nu$$ $$BIC = L + \\log(n)\\nu$$ $$GCV = \\frac{L}{(1-\\nu/n)^2}$$ $$AICc = AIC + 2\\frac{\\nu(\\nu+1)}{n-\\nu-1}$$ $$EBIC = BIC + 2 \\log{p \\choose \\nu}$$","code":""},{"path":[]},{"path":"/reference/select.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Select an value of lambda along a grpreg path — select","text":"","code":"data(Birthwt) X <- Birthwt$X y <- Birthwt$bwt group <- Birthwt$group fit <- grpreg(X, y, group, penalty=\"grLasso\") select(fit) #> $beta #> (Intercept)        age1        age2        age3        lwt1        lwt2  #>  3.02536524  0.12945631  0.51415003  0.30726166  0.62868704 -0.15121567  #>        lwt3       white       black       smoke        ptl1       ptl2m  #>  0.49385428  0.16776254 -0.05345302 -0.17442566 -0.15785358  0.04441707  #>          ht          ui        ftv1        ftv2       ftv3m  #> -0.26670074 -0.36973445  0.00000000  0.00000000  0.00000000  #>  #> $lambda #> [1] 0.05613761 #>  #> $df #> [1] 7.802936 #>  #> $IC #>   [1] 426.4719 424.3328 422.5671 421.1159 419.9288 418.7393 417.4156 414.7527 #>   [9] 412.1531 410.0387 408.2984 407.0545 406.2688 405.8647 405.7733 405.9338 #>  [17] 406.2932 406.8058 407.4328 408.8683 410.5842 412.2879 413.9583 415.5797 #>  [25] 417.1405 418.6325 420.0505 421.3916 422.6544 423.8392 424.9472 425.9806 #>  [33] 426.9421 427.8346 428.6616 429.4265 430.1331 430.7847 431.3851 431.9377 #>  [41] 432.4457 432.9124 433.3408 433.7338 434.0940 434.4240 434.7262 435.0029 #>  [49] 435.2559 435.4874 435.6990 435.8924 436.0691 436.2306 436.3780 436.5126 #>  [57] 436.6355 436.7477 436.8501 436.9435 437.0287 437.1064 437.1774 437.2420 #>  [65] 437.3010 437.3548 437.4039 437.4486 437.4894 437.5265 437.5604 437.5913 #>  [73] 437.6195 437.6452 437.6685 437.6899 437.7093 437.7270 437.7432 437.7579 #>  [81] 437.7713 437.7835 437.7946 437.8048 437.8140 437.8225 437.8302 437.8371 #>  [89] 437.8435 437.8493 437.8546 437.8595 437.8639 437.8679 437.8715 437.8748 #>  [97] 437.8779 437.8806 437.8831 437.8854 #>  select(fit,crit=\"AIC\",df=\"active\") #> Warning: minimum lambda selected for grLasso #> $beta #> (Intercept)        age1        age2        age3        lwt1        lwt2  #>  3.04927431 -0.08976451  1.59151760  0.90968052  1.93600738  0.07121398  #>        lwt3       white       black       smoke        ptl1       ptl2m  #>  1.38273076  0.29582051 -0.15808854 -0.28371611 -0.29193287  0.23107109  #>          ht          ui        ftv1        ftv2       ftv3m  #> -0.56800347 -0.48190866  0.08817371  0.02497665 -0.17027810  #>  #> $lambda #> [1] 2.064955e-05 #>  #> $df #> [1] 18 #>  #> $IC #>   0.2065   0.1882   0.1714   0.1562   0.1423   0.1297   0.1182   0.1077  #> 419.9884 419.3837 417.1936 415.3559 413.8165 414.1508 412.1160 417.1816  #>   0.0981   0.0894   0.0814   0.0742   0.0676   0.0616   0.0561   0.0512  #> 411.8883 412.8994 413.0615 407.4569 402.6136 398.4455 394.8722 391.8192  #>   0.0466   0.0425   0.0387   0.0353   0.0321   0.0293   0.0267   0.0243  #> 389.2187 387.0097 385.1378 389.3600 387.7910 386.4642 385.3446 384.4016  #>   0.0221   0.0202   0.0184   0.0167   0.0153   0.0139   0.0127   0.0115  #> 383.6086 382.9427 382.3843 381.9166 381.5251 381.1978 380.9244 380.6961  #>   0.0105   0.0096   0.0087    0.008   0.0073   0.0066    0.006   0.0055  #> 380.5056 380.3468 380.2144 380.1040 380.0121 379.9357 379.8720 379.8190  #>    0.005   0.0046   0.0041   0.0038   0.0034   0.0031   0.0029   0.0026  #> 379.7749 379.7382 379.7077 379.6823 379.6612 379.6437 379.6291 379.6170  #>   0.0024   0.0022    0.002   0.0018   0.0016   0.0015   0.0014   0.0012  #> 379.6069 379.5986 379.5916 379.5858 379.5810 379.5770 379.5738 379.5710  #>   0.0011    0.001    9e-04    9e-04    8e-04    7e-04    6e-04    6e-04  #> 379.5687 379.5668 379.5652 379.5639 379.5628 379.5619 379.5612 379.5606  #>    5e-04    5e-04    4e-04    4e-04    4e-04    3e-04    3e-04    3e-04  #> 379.5601 379.5596 379.5593 379.5590 379.5587 379.5585 379.5584 379.5582  #>    3e-04    2e-04    2e-04    2e-04    2e-04    2e-04    1e-04    1e-04  #> 379.5581 379.5580 379.5579 379.5579 379.5578 379.5578 379.5577 379.5577  #>    1e-04    1e-04    1e-04    1e-04    1e-04    1e-04    1e-04    1e-04  #> 379.5577 379.5576 379.5576 379.5576 379.5576 379.5576 379.5576 379.5576  #>    1e-04    1e-04        0        0        0        0        0        0  #> 379.5576 379.5575 379.5575 379.5575 379.5575 379.5575 379.5575 379.5575  #>        0        0        0        0  #> 379.5575 379.5575 379.5575 379.5575  #>  plot(fit) abline(v=select(fit)$lambda)  par(mfrow=c(1,3)) l <- fit$lambda xlim <- rev(range(l)) plot(l, select(fit)$IC, xlim=xlim, pch=19, type=\"o\", ylab=\"BIC\") plot(l, select(fit,\"AIC\")$IC, xlim=xlim, pch=19, type=\"o\",ylab=\"AIC\") plot(l, select(fit,\"GCV\")$IC, xlim=xlim, pch=19, type=\"o\",ylab=\"GCV\")"},{"path":"/reference/summary.cv.grpreg.html","id":null,"dir":"Reference","previous_headings":"","what":"Summarizing inferences based on cross-validation — summary.cv.grpreg","title":"Summarizing inferences based on cross-validation — summary.cv.grpreg","text":"Summary method cv.grpreg cv.grpsurv objects","code":""},{"path":"/reference/summary.cv.grpreg.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summarizing inferences based on cross-validation — summary.cv.grpreg","text":"","code":"# S3 method for class 'cv.grpreg' summary(object, ...)  # S3 method for class 'summary.cv.grpreg' print(x, digits, ...)"},{"path":"/reference/summary.cv.grpreg.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summarizing inferences based on cross-validation — summary.cv.grpreg","text":"object \"cv.grpreg\" object. ... arguments passed methods. x \"summary.cv.grpreg\" object. digits Number digits past decimal point print .  Can vector specifying different display digits five non-integer printed values.","code":""},{"path":"/reference/summary.cv.grpreg.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summarizing inferences based on cross-validation — summary.cv.grpreg","text":"summary(cvfit) produces object S3 class \"summary.cv.grpreg\".  class print method contains following list elements: penalty penalty used grpreg/grpsurv. model type model: \"linear\", \"logistic\", \"Poisson\", \"Cox\", etc. n Number observations p Number regression coefficients (including intercept). min index lambda smallest cross-validation error. lambda sequence lambda values used cv.grpreg/cv.grpsurv. cve Cross-validation error (deviance). r.squared Proportion variance explained model, estimated cross-validation. snr Signal noise ratio, estimated cross-validation. sigma linear regression models, scale parameter estimate. pe logistic regression models, prediction error (misclassification error).","code":""},{"path":[]},{"path":"/reference/summary.cv.grpreg.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Summarizing inferences based on cross-validation — summary.cv.grpreg","text":"Patrick Breheny","code":""},{"path":"/reference/summary.cv.grpreg.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Summarizing inferences based on cross-validation — summary.cv.grpreg","text":"","code":"# Birthweight data data(Birthwt) X <- Birthwt$X group <- Birthwt$group  # Linear regression y <- Birthwt$bwt cvfit <- cv.grpreg(X, y, group) summary(cvfit) #> grLasso-penalized linear regression with n=189, p=16 #> At minimum cross-validation error (lambda=0.0167): #> ------------------------------------------------- #>   Nonzero coefficients: 16 #>   Nonzero groups: 8 #>   Cross-validation error of 0.43 #>   Maximum R-squared: 0.18 #>   Maximum signal-to-noise ratio: 0.22 #>   Scale estimate (sigma) at lambda.min: 0.659  # Logistic regression y <- Birthwt$low cvfit <- cv.grpreg(X, y, group, family=\"binomial\") summary(cvfit) #> grLasso-penalized logistic regression with n=189, p=16 #> At minimum cross-validation error (lambda=0.0136): #> ------------------------------------------------- #>   Nonzero coefficients: 16 #>   Nonzero groups: 8 #>   Cross-validation error of 1.12 #>   Maximum R-squared: 0.11 #>   Maximum signal-to-noise ratio: 0.10 #>   Prediction error at lambda.min: 0.291  # Cox regression data(Lung) cvfit <- with(Lung, cv.grpsurv(X, y, group)) summary(cvfit) #> grLasso-penalized Cox regression with n=137, p=14 #> At minimum cross-validation error (lambda=0.1063): #> ------------------------------------------------- #>   Nonzero coefficients: 7 #>   Nonzero groups: 2 #>   Cross-validation error of 7.60 #>   Maximum R-squared: 0.25 #>   Maximum signal-to-noise ratio: 0.04"},{"path":"/news/index.html","id":"grpreg-350-2024-09-03","dir":"Changelog","previous_headings":"","what":"grpreg 3.5.0 (2024-09-03)","title":"grpreg 3.5.0 (2024-09-03)","text":"Changed: grpreg()$loss longer returned New: plot_spline() now “add” option splines can added existing plot Fixed: Loss/deviance now used consistently throughout; see #52 Fixed: Fixed broken URLs Fixed: Fixed bug mean added twice cv.grpreg() Fixed: Bug SNR infinite Fixed: Passing seed longer affects global environment Fixed: cv.grpsurv() now sets default group supplied Fixed: error response constant; see #46 Fixed: error single lambda supplied Internal: Updated citation format bibentry() Internal: Now using R_Calloc R_USE_STRICT_R_HEADERS compatibility Documentation: Now using roxygen Documentation: Updated online documentation penalties","code":""},{"path":"/news/index.html","id":"grpreg-340-2021-07-22","dir":"Changelog","previous_headings":"","what":"grpreg 3.4.0 (2021-07-22)","title":"grpreg 3.4.0 (2021-07-22)","text":"CRAN release: 2021-07-26 New: Suite tools additive modeling, notably expand_spline() plot_spline() (thank Ryan Kurth work project) New: grpreg() now returns linear.predictors object New: grpreg() grpsurv() now residuals() methods New: predict.grpsurv() can now predict cumulative hazard (type=“hazard”) New: Can now perform cross-validation group bridge cv.grpreg() Changed: fit$y now returns original y, centered y Changed: grpsurv() now consistent grpreg() terms returning deviance (2*loss) groups factors Fixed: predict() longer converts factors strings type=“groups” Fixed: grpsurv() works correctly single feature supplied","code":""},{"path":"/news/index.html","id":"grpreg-331-2021-03-26","dir":"Changelog","previous_headings":"","what":"grpreg 3.3.1 (2021-03-26)","title":"grpreg 3.3.1 (2021-03-26)","text":"CRAN release: 2021-03-30 Fixed: AUC() now compatible survival 3.2.10 Fixed: predict() now works correctly cv.grpsurv objects Internal: Fixed memory leak Documentation: Better formatting references, DOIs","code":""},{"path":"/news/index.html","id":"grpreg-330-2020-06-10","dir":"Changelog","previous_headings":"","what":"grpreg 3.3.0 (2020-06-10)","title":"grpreg 3.3.0 (2020-06-10)","text":"CRAN release: 2020-06-10 Fixed: sqrt(K) longer hard-coded discarding rules (thank Dan Kessler pointing ) Testing: Now uses tinytest package Documentation: Removing references grpregOverlap (hope merge)","code":""},{"path":"/news/index.html","id":"grpreg-322-2020-02-14","dir":"Changelog","previous_headings":"","what":"grpreg 3.2.2 (2020-02-14)","title":"grpreg 3.2.2 (2020-02-14)","text":"CRAN release: 2020-02-19 Change: Better error detection ill-conditioned, unpenalized matrices Fixed: loss.grpsurv now works total=FALSE Internal: Lots internal changes cleaner, reliable code New version numbering system","code":""},{"path":"/news/index.html","id":"grpreg-32-1-2019-02-26","dir":"Changelog","previous_headings":"","what":"grpreg 3.2-1 (2019-02-26)","title":"grpreg 3.2-1 (2019-02-26)","text":"CRAN release: 2019-02-26 Change: Cross-validation now balances censoring across folds survival models Fixed: Leave-one-cross-validation now works correctly logistic regression","code":""},{"path":"/news/index.html","id":"grpreg-32-0-2018-09-27","dir":"Changelog","previous_headings":"","what":"grpreg 3.2-0 (2018-09-27)","title":"grpreg 3.2-0 (2018-09-27)","text":"CRAN release: 2018-09-27 New: cv.grpsurv now calculates SE, bootstrap option Change: R^2 now consistently uses Cox-Snell definition types models Change: Survival loss now uses deviance Change: cv.grpsurv now uses ‘fold’, ‘cv.ind’, declare assignments Fixed: cv.grpreg now correctly handles --order groups Poisson Fixed: cv.grpsurv now correctly standardizes --order groups Fixed: grpreg longer returns loss=NA family=‘binomial’ lambda values Internal: SSR-BEDPP optimization reinstated bug fix Internal: C code binom/pois combined gdfit_glm, lcdfit_glm Documentation: Lots updates Documentation: vignette now html (used pdf) Documentation: pkgdown website","code":""},{"path":"/news/index.html","id":"grpreg-31-4-2018-06-15","dir":"Changelog","previous_headings":"","what":"grpreg 3.1-4 (2018-06-15)","title":"grpreg 3.1-4 (2018-06-15)","text":"CRAN release: 2018-06-15 Fixed: Works arbitrarily “messy” group structures now (constant columns, order groups, etc.) due restructuring standardization/ orthogonalization Internal: SSR-BEDPP rule turned due bug","code":""},{"path":"/news/index.html","id":"grpreg-31-3-2018-04-07","dir":"Changelog","previous_headings":"","what":"grpreg 3.1-3 (2018-04-07)","title":"grpreg 3.1-3 (2018-04-07)","text":"CRAN release: 2018-04-08 Internal: C code now uses || instead |","code":""},{"path":"/news/index.html","id":"grpreg-31-2-2017-07-05","dir":"Changelog","previous_headings":"","what":"grpreg 3.1-2 (2017-07-05)","title":"grpreg 3.1-2 (2017-07-05)","text":"CRAN release: 2017-07-06 Fixed: Bug applying screening rules group lasso linear regression user-specified lambda sequence (thank much Natasha Sahr pointing )","code":""},{"path":"/news/index.html","id":"grpreg-31-1-2017-06-07","dir":"Changelog","previous_headings":"","what":"grpreg 3.1-1 (2017-06-07)","title":"grpreg 3.1-1 (2017-06-07)","text":"CRAN release: 2017-06-08 Fixed: Cross-validation longer fails constant columns present (thank Matthew Rosenberg pointing ) Fixed: Cross-validation longer fails group.multiplier specified","code":""},{"path":"/news/index.html","id":"grpreg-31-0-2017-05-18","dir":"Changelog","previous_headings":"","what":"grpreg 3.1-0 (2017-05-18)","title":"grpreg 3.1-0 (2017-05-18)","text":"CRAN release: 2017-05-18 New: Additional tests support coersion various types respect X y Change: Convergence criterion now based RMSD linear predictors Change: ‘Lung’ ‘Birthwt’ data sets now use factor representation group, character vectors inherently ambiguous respect order Change: max.iter now based total number iterations entire path Internal: ‘X’, ‘group’, ‘group.multiplier’ now bundled together object called ‘XG’ enforce agreement times Internal: new SSR-BEDPP feature screening rule group lasso Internal: Registration native routines Internal: Changing PROTECT/UNPROTECT conform new coding standards Fixed: binding X G fixes several potential bugs, including Issue #12 (GitHub)","code":""},{"path":"/news/index.html","id":"grpreg-30-2","dir":"Changelog","previous_headings":"","what":"grpreg 3.0-2","title":"grpreg 3.0-2","text":"CRAN release: 2016-07-11 Fixed bug involving mismatch group.multiplier group group given order.","code":""},{"path":"/news/index.html","id":"grpreg-30-1-2016-06-06","dir":"Changelog","previous_headings":"","what":"grpreg 3.0-1 (2016-06-06)","title":"grpreg 3.0-1 (2016-06-06)","text":"CRAN release: 2016-06-06 Fixed: memory allocation bug Deprecation: Re-introduced ‘birthwt.grpreg’ backwards compatibility, deprecated","code":""},{"path":"/news/index.html","id":"grpreg-30-0-2016-06-02","dir":"Changelog","previous_headings":"","what":"grpreg 3.0-0 (2016-06-02)","title":"grpreg 3.0-0 (2016-06-02)","text":"CRAN release: 2016-06-02 New: methods survival analysis (Cox modeling): grpsurv, cv.grpsurv, AUC, predict.grpsurv New: option return fitted values cross-validation folds (returnY=TRUE) cv.grpreg cv.grpsurv New: Added user interrupt checking Change: Reformatted (renamed) example data set ‘Birthwt’; added example data set ‘Lung’ survival Internal: Greatly expanded suite tests; various bugs identified fixed result Documentation: Added vignettes (quick-start guide detailed description available penalties)","code":""},{"path":"/news/index.html","id":"grpreg-28-1-2015-05-30","dir":"Changelog","previous_headings":"","what":"grpreg 2.8-1 (2015-05-30)","title":"grpreg 2.8-1 (2015-05-30)","text":"CRAN release: 2015-05-30 New: cv.grpreg now allows user specify lambda (thanks Vincent Arel-Bundock suggesting change) Fixed: bug predict.grpreg(fit, type=“nvars”) type=“ngroups” scalar lambda value passed Documentation: Updated citations","code":""},{"path":"/news/index.html","id":"grpreg-28-0-2014-11-15","dir":"Changelog","previous_headings":"","what":"grpreg 2.8-0 (2014-11-15)","title":"grpreg 2.8-0 (2014-11-15)","text":"CRAN release: 2014-11-15 New: flexible interface ‘group’ argument; groups may now order, may named rather consecutive integers New: ‘X’ can now matrix integers (previously result passing incompatible storage type C) New: Additional error checks prevent cryptic error messages Internal: modifications convergence monitoring New: Added corrected AIC extended BIC options select() Change: summary.cv.grpreg now describes multitask learning models accurately Fixed: bug multitask learning number outcomes = 2 (thank Aluma Dembo pointing ) Fixed: Cross-validation multitask learning now respects multivariate structure response matrix Fixed: bug cv.grpreg attempting use leave-one-cross-validation","code":""},{"path":"/news/index.html","id":"grpreg-27-1-2014-08-13","dir":"Changelog","previous_headings":"","what":"grpreg 2.7-1 (2014-08-13)","title":"grpreg 2.7-1 (2014-08-13)","text":"CRAN release: 2014-08-13 Fixed: rigorous initialization C level prevent possible memory access problems Fixed: predict() types ‘vars’, ‘nvars’, ‘ngroups’ multivariate outcomes Fixed: consequence fix, summary(cvfit) now works multivariate outcomes (thank Cajo ter Braak pointing broken)","code":""},{"path":"/news/index.html","id":"grpreg-27-0-2014-08-13","dir":"Changelog","previous_headings":"","what":"grpreg 2.7-0 (2014-08-13)","title":"grpreg 2.7-0 (2014-08-13)","text":"CRAN release: 2014-08-13 New: support Poisson regression Internal: .Call now used instead .C Fixed: bug cv.grpreg attempting use leave-one-cross-validation (thank Cajo ter Braak pointing )","code":""},{"path":"/news/index.html","id":"grpreg-26-0-2014-03-21","dir":"Changelog","previous_headings":"","what":"grpreg 2.6-0 (2014-03-21)","title":"grpreg 2.6-0 (2014-03-21)","text":"CRAN release: 2014-03-21 Internal: Various internal changes make package efficient large data sets","code":""},{"path":"/news/index.html","id":"grpreg-25-0-2013-12-24","dir":"Changelog","previous_headings":"","what":"grpreg 2.5-0 (2013-12-24)","title":"grpreg 2.5-0 (2013-12-24)","text":"CRAN release: 2013-12-24 New: group exponential lasso ‘gel’ method New: ‘gmax’ option New: ‘nvars’ ‘ngroups’ options predict Change: appearance summary.cv.grpreg display","code":""},{"path":"/news/index.html","id":"grpreg-24-0-2013-06-07","dir":"Changelog","previous_headings":"","what":"grpreg 2.4-0 (2013-06-07)","title":"grpreg 2.4-0 (2013-06-07)","text":"CRAN release: 2013-06-07 New: options plot.cv.grpreg plot estimates r-squared, signal--noise ratio, scale parameter, prediction error addition cross-validation error (deviance) New: grpreg cv.grpreg now allow matrix y facilitation group penalized methods seemingly unrelated regressions/multitask learning. something ‘beta’ release point, developed refined future releases. New: ‘summary’ method cv.grpreg objects New: ‘coef’ ‘predict’ methods cv.grpreg objects Change: Brought gBridge date now handles constant columns, etc. (see # grpreg 2.2-0) Fixed: bug predict type=‘coefficients’ ‘lambda’ argument specified Fixed: bug cv.grpreg user-defined lambda values","code":""},{"path":"/news/index.html","id":"grpreg-23-0-2013-02-10","dir":"Changelog","previous_headings":"","what":"grpreg 2.3-0 (2013-02-10)","title":"grpreg 2.3-0 (2013-02-10)","text":"CRAN release: 2013-02-10 Internal: Switched SVD-based orthogonalization allow linear dependency within groups","code":""},{"path":"/news/index.html","id":"grpreg-22-1-2012-11-16","dir":"Changelog","previous_headings":"","what":"grpreg 2.2-1 (2012-11-16)","title":"grpreg 2.2-1 (2012-11-16)","text":"CRAN release: 2012-11-15 Fixed: compilation error 32-bit Windows Fixed: bug calculation binomial deviance fitted probabilities close 0 1","code":""},{"path":"/news/index.html","id":"grpreg-22-0-2012-10-09","dir":"Changelog","previous_headings":"","what":"grpreg 2.2-0 (2012-10-09)","title":"grpreg 2.2-0 (2012-10-09)","text":"CRAN release: 2012-10-09 New: select now Now allows ‘…’ options passed logLik New: Added option plot norm group, rather individual coefficients New: ‘vars’, ‘groups’, ‘norm’ options added ‘predict’ Change: cv.grpreg now returns full data fit well CV errors; allows cv.grpreg handle constant columns fixes bugs Fixed: logLik longer calculates (meaningless) log-likelihoods saturated models (thank Xiaowei Ren pointing ) Fixed: bug returning group groups eliminated due constant columns","code":""},{"path":"/news/index.html","id":"grpreg-21-0-2012-07-28","dir":"Changelog","previous_headings":"","what":"grpreg 2.1-0 (2012-07-28)","title":"grpreg 2.1-0 (2012-07-28)","text":"CRAN release: 2012-07-28 New: grpreg can now handle constant columns (produce beta=0) Fixed: Bug involving orthogonalization unpenalized groups Internal: restructuring C code","code":""},{"path":"/news/index.html","id":"grpreg-20-0-2012-07-21","dir":"Changelog","previous_headings":"","what":"grpreg 2.0-0 (2012-07-21)","title":"grpreg 2.0-0 (2012-07-21)","text":"CRAN release: 2012-07-21 New: Group MCP, group SCAD methods added New: Added ‘cv.grpreg’ facilitate cross-validation New: ‘dfmax’ option New: ‘group.multiplier’ option New: Allows specification unpenalized groups Change: gBridge now divorced grpreg given separate function Internal: New algorithm group lasso Internal: Extensive internal refactoring code Internal: standardize orthogonalize functions added Internal: Much extensive reproducible code testing","code":""},{"path":"/news/index.html","id":"grpreg-12-0-2011-06-22","dir":"Changelog","previous_headings":"","what":"grpreg 1.2-0 (2011-06-22)","title":"grpreg 1.2-0 (2011-06-22)","text":"CRAN release: 2011-06-22 New: grpreg now returns ‘loss’ New: Added logLik method Change: Syntax ‘select’ modified (longer requires X, y passed) Change: ‘plot.grpreg’ function flexible Change: ‘n.lambda’ ‘nlambda’ grpreg Change: ‘’ ‘gamma’ MCP tuning parameter Change: ‘lambda2’ ‘alpha’ Removed: ‘monitor’ longer option grpreg Removed: ‘criteria’ option select Fixed: Bug calculation df gLasso (grpreg.c) Documendation: Updated citation contact information","code":""}]
